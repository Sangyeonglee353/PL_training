{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913567b5",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "## 학번: 2019136151 이름: 이상영\n",
    "## [정보]\n",
    "#### 1) Due Date: 2021년 12월 11일 (토), 23시 59분\n",
    "#### 2) 제출방법: 수업 홈페이지 하단의 \"[숙제 제출 방법]\" 참고\n",
    "#### 3) 내용: 반드시 python code와 수행 결과를 jupyter notebook 내에 작성하여 넣고, 이에 대한 설명 등을 해당 코드 아래에 markdown cell 등에 넣어 기입하시오.\n",
    "#### 4) 숙제이후 소감 작성: 다음 문제의 답을 모두 작성한 이후에 현재까지 강의를 들은 후의 소감, 숙제를 한 이후의 소감, 또는 전하고자 하는 말 등을 짧막하게라도 좋으니 jupyter notebook 마지막 markdown cell에 함께 제출하시오.  \n",
    "#### 5) 반드시 본인 스스로 문제를 해결하세요~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72dc2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bfdcb",
   "metadata": {},
   "source": [
    "## [일반 문제]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5841de",
   "metadata": {},
   "source": [
    "#### 1. 클래스와 모듈의 공통점과 차이점에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd55a6f",
   "metadata": {},
   "source": [
    "__[클래스와 모듈의 공통점]__   \n",
    "(1) 중복된 코드의 재작성을 줄일 수 있다.   \n",
    "(2) 별도의 이름공간을 제공한다.   \n",
    "(3) 용도에 맞도록 구성한 객체 멤버들을 캡슐화 시킨 후 가져다 사용한다.   \n",
    "\n",
    "__[클래스와 모듈의 차이점]__   \n",
    "(1) 클래스는 상속을 통한 인스턴스화, 인터페이스 구현이 가능하지만, 모듈은 불가능하다.    \n",
    "(2) 클래스의 이름 공간: 클래스 영역 내 이름 공간, 모듈의 이름 공간: 파일 단위로 이름 공간을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa557e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c09df",
   "metadata": {},
   "source": [
    "#### 2. 다형성에 대해 설명하고 다형성을 보여주는 자신만의 파이썬 코드 예제를 제시하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55aa86e",
   "metadata": {},
   "source": [
    "__다형성이란?__   \n",
    "- 다른 클래스에 속한 같은 이름의 인스턴스들이 동일한 메소드 이름으로 호출될 경우 동적으로 선택되어 수행되는 것을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f561e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diagram:\n",
    "    def area(self):\n",
    "        return \"도형입니다.\"\n",
    "    \n",
    "class Rectangle(Diagram):\n",
    "    def area(self, weight, height):\n",
    "        return weight*height\n",
    "\n",
    "class Circle(Diagram):\n",
    "    def area(self, radian):\n",
    "        return radian * radian * 3.141592\n",
    "    \n",
    "class Triangle(Diagram):\n",
    "    def area(self, weight, height):\n",
    "        return weight*height/2\n",
    "    \n",
    "class Cube(Diagram):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c685266",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Rectangle()\n",
    "b = Circle()\n",
    "c = Triangle()\n",
    "d = Cube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef6b4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangle area: 15\n",
      "Circle area: 78.5398\n",
      "Triangle area: 5.0\n",
      "Cube area: 도형입니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"Rectangle area: {}\".format(a.area(3, 5)))\n",
    "print(\"Circle area: {}\".format(b.area(5)))\n",
    "print(\"Triangle area: {}\".format(c.area(2, 5)))\n",
    "print(\"Cube area: {}\".format(d.area()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883b198",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c9d76",
   "metadata": {},
   "source": [
    "#### 3. 다음 각 요구사항 모두를 만족시키는 Counter 클래스를 코딩하시오. (정답을 각 요구사항별로 입력할 필요없이 3번 문제에 대해 1개의 클래스 정의 코드를 제시하면 된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7c2e6",
   "metadata": {},
   "source": [
    "- 요구사항 1. 생성자에 count 값과 step 값을 인자로 받을 수 있다.\n",
    "    - count: Counter 인스턴스가 지니는 초기 정수 값\n",
    "    - step: Counter 인스턴스의 count가 증가되는 증분 (default 값: 1)\n",
    "\n",
    "  > <html>>>> c = Counter(10)<br>\n",
    "    >>>> d = Counter(10, 2)</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd53303",
   "metadata": {},
   "source": [
    "- 요구사항 2. 다음과 같이 Counter의 인스턴스를 출력을 해주는 __str__() 메소드를 Counter 클래스 내에 구현하시오.\n",
    "> <html>>>> print(c)<br>\n",
    "    [Count (step: 1)] 10<br>\n",
    "    >>>> print(d)<br>\n",
    "    [Count (step: 2)] 10<br></html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a53c7",
   "metadata": {},
   "source": [
    "- 요구사항 3. 다음과 같이 step에 주어진 증분만큼 count를 증가시키는 incr() 메소드르 Counter 클래스 내에 구현하시오.   \n",
    "> <html>>>> c.incr()<br>\n",
    "    >>>> d.incr()<br>\n",
    "    >>>> print(c)<br>\n",
    "    [Count (step: 1)] 11<br>\n",
    "    >>>> print(d)<br>\n",
    "    [Count (step: 2)] 12</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f5a56",
   "metadata": {},
   "source": [
    "- 요구사항 4. Counter 클래스 내에 관련 메소드를 추가하여 인스턴스 객체를 직접 호출(call)할 수 있도록 하시오. 인스턴스 객체를 직접 호출했을 때에 내부적으로 incr() 메소드를 호출하는 방법으로 구현하시오.   \n",
    "> <html>>>> c()<br>\n",
    "    >>>> d()<br>\n",
    "    >>>> print(c)<br>\n",
    "    [Count (step: 1)] 12<br>\n",
    "    >>>> print(d)<br>\n",
    "    [Count (step: 2)] 14</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d2466",
   "metadata": {},
   "source": [
    "- 요구사항 5. 다음과 같은 두 개의 산술 연산(+, -)이 수행될 수 있도록 Counter 클래스 내에 관련 메소드를 추가하시오.   \n",
    "> <html>>>> c = c + 5<br>\n",
    "    >>>> d = d - 5<br>\n",
    "    >>>> print(c)<br>\n",
    "    [Count (step: 1)] 17<br>\n",
    "    >>>> print(d)<br>\n",
    "    [Count (step: 2)] 9</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f9a2b",
   "metadata": {},
   "source": [
    "- 요구사항 6. 다음과 같은 관계연산(>, <, ==)이 수행될 수 있도록 Counter 클래스 내에 관련 메소드를 추가하시오.   \n",
    "> <html>>>> print(c > 10)<br>\n",
    "    True<br>\n",
    "    >>>> print(d > 10)<br>\n",
    "    False<br>\n",
    "    >>>> print(c < 10)<br>\n",
    "    False<br>\n",
    "    >>>> print(d < 10)<br>\n",
    "    True<br>\n",
    "    >>>> print(c == 17)<br>\n",
    "    True<br>\n",
    "    >>>> print(d != 9)<br>\n",
    "    False</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b867a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    # 요구사항 1\n",
    "    def __init__(self, count, step=1):\n",
    "        self.count = count\n",
    "        self.step = step\n",
    "    # 요구사항 2\n",
    "    def __str__(self):\n",
    "        return \"[Count (step: {})] {}\".format(self.step, self.count)\n",
    "    # 요구사항 3\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "        return self\n",
    "    # 요구사항 4\n",
    "    def __call__(self):\n",
    "        self.incr()\n",
    "    # 요구사항 5 -> 출력 방법 1 사용\n",
    "    def __add__(self, num):\n",
    "        self.count += num\n",
    "        return self\n",
    "    def __sub__(self, num):\n",
    "        self.count -= num\n",
    "        return self\n",
    "    # 요구사항 6 -> 출력 방법 2 사용\n",
    "    def __gt__(self, num):\n",
    "        return self.count > num\n",
    "    def __lt__(self, num):\n",
    "        return self.count < num\n",
    "    def __eq__(self, num):\n",
    "        return self.count == num\n",
    "    def __ne__(self, num):\n",
    "        return self.count != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bab02efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요구사항 1\n",
    "c = Counter(10)\n",
    "d = Counter(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cf575de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count (step: 1)] 10\n",
      "[Count (step: 2)] 10\n"
     ]
    }
   ],
   "source": [
    "# 요구사항 2\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a10603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count (step: 1)] 11\n",
      "[Count (step: 2)] 12\n"
     ]
    }
   ],
   "source": [
    "# 요구사항 3\n",
    "c.incr()\n",
    "d.incr()\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "33b1c110",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count (step: 1)] 12\n",
      "[Count (step: 2)] 14\n"
     ]
    }
   ],
   "source": [
    "# 요구사항 4\n",
    "c()\n",
    "d()\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eca93c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count (step: 1)] 17\n",
      "[Count (step: 2)] 9\n"
     ]
    }
   ],
   "source": [
    "# 요구사항 5\n",
    "c = c + 5\n",
    "d = d - 5\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5af4e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 요구사항 6\n",
    "print(c > 10)\n",
    "print(d > 10)\n",
    "print(c < 10)\n",
    "print(d < 10)\n",
    "print(c == 17)\n",
    "print(d != 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a813b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bc8ad",
   "metadata": {},
   "source": [
    "#### 4. 다음은 내장 자료형 list를 서브클래싱하여 만든 MySet 클래스 정의 내용이다. 다음 클래스 정의에서 __init__(), __str()__, elimicate_duplicate()의 세 개의 메소드 코드 내용을 자신이 다른 사람에게 가르친다고 생각하며 설명해보시오.   \n",
    "   - MySet은 집합(Set) 자료형을 정의하려는 의도하에 만들어진 클래스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08679c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3}\n",
      "MySet: {2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    print(s)\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632235ab",
   "metadata": {},
   "source": [
    "<html><b>[__init__() 메소드]</b><br></html>\n",
    "기본적으로 __init__() 메소드는 생성자 메소드로서 객체가 생성될 때 자동으로 불리어지는 메소드이다. 일반적으로 객체가 보유해야 할 변수나 자원들의 초기화 코드를 작성하며, 인자로는 self가 반드시 정의되어야 한다.<br>\n",
    "현재 MySet(list) 클래스에서는 for() 반복문을 이용해 입력받은 list(리스트)에 대해서 l이라는 리스트에 초기화해주고 있으며, 반복문이 끝나면 아래에 선언해둔 정적 메소드 eliminate_duplicate()를 통해 l 리스트에 중복값을 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ae7dd",
   "metadata": {},
   "source": [
    "<html><b>[__str__() 메소드]</b><br></html>\n",
    "__str__() 메소드는 객체를 지원하는 매직 메소드 중 하나로 사용자가 원하는 형태로 객체 데이터를 담아 문자열을 반환하고자 할 때 오버라이딩하여 사용한다.<br>\n",
    "현재 MySet(list) 클래스에서는 \"MySet: {...}\" 형태로 결과값을 출력하고자 for() 반복문으로 리스트의 값을 \",\" 반점과 함께 추가하고, 슬라이싱을 통해 마지막 \",\" 반점은 출력되지 않도록 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8c455",
   "metadata": {},
   "source": [
    "<html><b>[eliminate_duplicate() 메소드]</b><br></html>\n",
    "eliminate_duplicate() 메소드는 @staticmethod 를 통해 정적 메소드로 선언된 메소드이다.\n",
    "<br>1. 해당 메소드에서는 s 라는 빈 리스트를 만들고, <br> 2. 인자로 받은 l 리스트에 요소를 s 리스트에 추가하였는데, 이 때 if 조건문을 사용하여 s 리스트에 추가하려는 l 리스트의 요소 값이 없는 경우에만 추가하도록 하여 중복값을 제거하였다. <br> 3. 모든 반복문이 종료된 뒤에는 l 리스트를 빈 문자열로 만든 뒤, 이것을 s 리스트의 값으로 초기화해주었다.<br> 여기서 <b>정적 메소드</b>란?<br>\n",
    "인스턴스를 만들지 않아도 class의 메소드를 바로 실행할 수 있는 특징을 가진 메소드인데, 파이썬에서는 이 정적 메소드를 두 가지 방법으로 지원하고 있다. 첫번째가 위와 같이 @staticmethod 형태이고 두번째가 @classmethod 형태이다. @staticmethod 는 특별이 추가되는 인자가 없는 반면, @classmethod는 첫번째 인자로 클래스가 추가된다는 특징이 있다. 이 둘의 차이는 상속에서 두드러지게 나타나는데 이에 대해서는 아래의 예제를 참고하면 이해하기 쉽다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c41debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    default_language = \"English\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.show = '나의 언어는' + self.default_language\n",
    "\n",
    "    @classmethod\n",
    "    def class_my_language(cls):\n",
    "        return cls()\n",
    "\n",
    "    @staticmethod\n",
    "    def static_my_language():\n",
    "        return Language()\n",
    "\n",
    "    def print_language(self):\n",
    "        print(self.show)\n",
    "\n",
    "\n",
    "class KoreanLanguage(Language):\n",
    "    default_language = \"한국어\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f19db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KoreanLanguage.static_my_language()\n",
    "b = KoreanLanguage.class_my_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc9b614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 언어는English\n",
      "나의 언어는한국어\n"
     ]
    }
   ],
   "source": [
    "a.print_language()\n",
    "b.print_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6555483b",
   "metadata": {},
   "source": [
    "이처럼 @staticmethod는 부모 클래스의 클래스 속성값을 가져오지만, @classmethod에서는 cls인자를 활용하여 cls의 클래스 속성을 가져오는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94081fd",
   "metadata": {},
   "source": [
    "[예제 출처]\n",
    "https://wikidocs.net/16074"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c853817",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63987451",
   "metadata": {},
   "source": [
    "#### 5. 4번 문제에 정의된 MySet 클래스에 메소드를 추가하여 다음 각 요구사항 모두를 만족시키는 코딩을 제시하시오.\n",
    "   - 정답을 각 요구사항별로 입력할 필요 없이 요구사항 3개 전체에 대해 1개의 MySet 클래스 정의 코드를 제시하고 주석 등으로 해당 코드를 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dfe62f",
   "metadata": {},
   "source": [
    " - 요구사항 1. | 연산으로 두 집합의 합집합을 반환한다.\n",
    "    ><html>>>> u = s | t<br>\n",
    "    >>>> print(u)<br>\n",
    "    MySet: {1, 2, 3, 4, 5, 6, 7, 8, 9}</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4656a",
   "metadata": {},
   "source": [
    " - 요구사항 2. & 연산으로 두 집합의 교집합을 반환한다.\n",
    "    ><html>>>> u = s & t<br>\n",
    "    >>>> print(u)<br>\n",
    "    MySet: {2, 3}</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841f8ea",
   "metadata": {},
   "source": [
    " - 요구사항 3. - 연산으로 두 집합의 차집합을 반환한다.\n",
    "    ><html>>>> s = MySet([1, 2, 3])<br>\n",
    "    >>>> t = MySet([3, 4, 5])<br>\n",
    "    >>>> u = s - t\n",
    "    >>>> print(u)<br>\n",
    "    MySet: {1, 2}</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdc5f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3}\n",
      "MySet: {2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n",
      "MySet: {1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n",
      "MySet: {2 ,3}\n",
      "MySet: {1 ,2}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "            \n",
    "    # 요구사항 1. | 연산으로 두 집합의 합집합 구현을 위한 __or__() 오버라이딩\n",
    "    def __or__(self, l):\n",
    "        orList = self + l\n",
    "        return MySet(orList)\n",
    "    \n",
    "    # 요구사항 2. & 연산으로 두 집합의 교집합 구현을 위한 __and__() 오버라이딩\n",
    "    def __and__(self, l):\n",
    "        andList = []\n",
    "        for element in self:\n",
    "            if element in l:\n",
    "                andList.append(element)                \n",
    "        return MySet(andList)\n",
    "\n",
    "    # 요구사항 3. - 연산으로 두 집합의 차집합 구현을 위한 __sub__() 오버라이딩\n",
    "    def __sub__(self, l):\n",
    "        # 3.1 교집합 리스트 구하기\n",
    "        andList = []\n",
    "        for element in self:\n",
    "            if element in l:\n",
    "                andList.append(element)\n",
    "        # 3.2 차집합 리스트: 현재 리스트에서 교집합 요소를 제외\n",
    "        subList = []\n",
    "        for element in self:\n",
    "            if element not in andList:\n",
    "                subList.append(element)          \n",
    "        return MySet(subList)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    print(s)\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    print(t)\n",
    "    # 요구사항 1. l 연산으로 두 집합의 합집합 구현\n",
    "    u = s | t\n",
    "    print(u)\n",
    "    # 요구사항 2. & 연산으로 두 집합의 교집합 구현\n",
    "    u = s & t\n",
    "    print(u)\n",
    "    # 요구사항 3. - 연산으로 두 집합의 차집합 구현\n",
    "    s = MySet([1, 2, 3])\n",
    "    t = MySet([3, 4, 5])\n",
    "    u = s - t\n",
    "    print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53858d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523a73f",
   "metadata": {},
   "source": [
    "#### 6. 5번 문제에서 정의한 MySet 클래스에 대해 다음 예제를 수행하면 오류없이 올바르게 동작하는 것을 확인할 수 있다. 다음 예제 내에 있는 len(), bool() 내장함수와 in 키워드 사용 예제가 별다른 메소드 정의를 하지 않았는 데도 올바르게 수행되는 이유를 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65605238",
   "metadata": {},
   "source": [
    ">\\>>> s = MySet([1, 2, 3, 4, 5, 6])<br>\n",
    ">\\>>> print(len(s))<br>\n",
    "\\> 6<br>\n",
    ">\\>>> print(bool(s))<br>\n",
    "\\> True<br>\n",
    ">\\>>> print(2 in s)<br>\n",
    "\\> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "309df909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "s = MySet([1, 2, 3, 4, 5, 6])\n",
    "print(len(s))\n",
    "print(bool(s))\n",
    "print(2 in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2af41",
   "metadata": {},
   "source": [
    "__[올바르게 수행되는 이유]__   \n",
    "클래스 내부에서 내부에 선언된 메소드 중 self를 붙이지 않고, 호출 시 이는 내부 메소드를 호출하는 것이 아닌 클래스 밖의 외부 메소드를 찾아 호출하게 된다. 따라서 이는 우리가 클래스 안에서 list() 나 dict() 등의 메소드를 사용할 수 있는 것과도 관련이 있는데, 이처럼 내장함수로 이미 선언된 함수의 경우, 별도로 함수를 선언하지 않고도 사용이 가능하다. 따라서, len(), bool()을 따로 정의하지 않았지만 내장함수이므로 올바르게 수행된다. in 키워드도 파이썬에서 특정 기능을 수행하도록 미리 예약된 예약어 중 하나로 별도의 정의 없이 사용이 가능하다.   \n",
    "__[참고 리스트]__   \n",
    "1. 내장함수 목록은 <b>dir(\\_\\_builtin__)</b> 명령어를 통해 아래처럼 확인이 가능하다.\n",
    "2. 예약어는 keyword 모듈을 삽입하여 keyword.kwlist 명령어를 통해 확인이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9f7edfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__and__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__weakref__', 'append', 'clear', 'copy', 'count', 'eliminate_duplicate', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
     ]
    }
   ],
   "source": [
    "# MySet() 클래스의 메소드\n",
    "print(dir(MySet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a8af329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '__IPYTHON__', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n"
     ]
    }
   ],
   "source": [
    "# 내장 함수(메소드)\n",
    "print(dir(__builtin__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45e62f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬의 예약어\n",
    "import keyword\n",
    "print(keyword.kwlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645e31d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3314d9",
   "metadata": {},
   "source": [
    "## [Incremental Project 문제]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb29f75",
   "metadata": {},
   "source": [
    "#### 1. Assignment 3 & Assignment 4의 Incremental Project 코드를 다시 확장/변형하여 다음과 같은 조건을 만족하도록 구현하시오 (CODE REFACTORING!!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a85c34",
   "metadata": {},
   "source": [
    "- 1) 새로운 클래스 SerachEngine를 정의하시오.\n",
    "    - 이전 숙제에서 고려했던 pickle 모듈 등은 전혀 고려하지 마시오.\n",
    "        - 즉, 하드디스크에 저장하고 다시 로드하는 기능은 본 숙제에는 배제하시오.\n",
    "    - 이전 숙제에서 적용했던 국어/영어 불용어 처리는 적용하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096dd205",
   "metadata": {},
   "source": [
    "- 2) 생성자에 URL을 0개에서 임의의 개수를 넣을 수 있도록 생성자 인수를 가변인수로 정의하여 각각의 URL을 리스트 자료형에 유지하시오.\n",
    "\n",
    ">\\>>> w1 = SearchEngine('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com')<br>\n",
    ">\\>>> w2 = SearchEngine('http://www.cnn.com', 'http://www.times.com')<br>\n",
    ">\\>>> w3 = SearchEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286f6a3",
   "metadata": {},
   "source": [
    "- 3) addUrl() 메소드를 구현하여 인스턴스를 생성한 이후에도 URL을 추가할 수 있도록 한다.\n",
    "    - 반드시 1개의 URL을 추가하도록 구현 (즉, 동시에 여러 개의 URL을 추가하는 것은 배제)\n",
    "    \n",
    ">\\>>> w1.addUrl('https://github.com')<br>\n",
    ">\\>>> w3.addUrl('http://stackoverflow.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020803d",
   "metadata": {},
   "source": [
    "- 4) removeUrl() 메소드를 구현하여 URL을 삭제할 수 있도록 한다.   \n",
    "    - 반드시 1개의 URL을 삭제하도록 구현 (즉, 동시에 여러 개의 URL을 삭제하는 것은 배제)\n",
    "    \n",
    ">\\>>> w1.removeUrl('http://www.cnn.com')<br>\n",
    ">\\>>> w2.removeUrl('http://stackoverflow.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24c966",
   "metadata": {},
   "source": [
    "- 5) listUrls() 메소드를 구현하여 현재 등록된 모든 URL을 출력하는 기능을 추가   \n",
    "\n",
    ">\\>>> w1.listUrls()<br>\n",
    "http://www.times.com<br>\n",
    "https://www.amazon.com<br>\n",
    "https://github.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc830b9",
   "metadata": {},
   "source": [
    "- 6) getWordsFrequency() 메소드를 구현하여 각 URL의 웹페이지들을 종합적으로 분석한 단어 출현 빈도 사전을 반환하시오.   \n",
    "    - 만약 등록된 URL이 없다면 공백 사전을 반환\n",
    "    \n",
    ">\\>>> w1.getWordsFrequency()<br>\n",
    "{'hello': 8, 'site': 12, 'world': 2, 'science': 11, 'program': 1, 'python': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98cc8f",
   "metadata": {},
   "source": [
    "- 7) getMaxFrequencyWords() 메소드를 구현하여 각 URL의 웹페이지들을 종합적으로 분석한 단어 출현 빈도 사전에서 가장 많이 출현한 단어 리스트를 반환하시오.\n",
    "\n",
    ">\\>>> w1.getMaxFrequencyWords()<br>\n",
    "{'site': 12}<br>\n",
    "\n",
    "- 최다 출현 단어의 빈도수가 동일한 경우 모두 출력해주어야 함\n",
    "    \n",
    ">\\>>> w2.getMaxFrequencyWords()<br>\n",
    "{'site': 12, 'science': 12}<br>\n",
    "\n",
    "- 만약 등록된 URL이 없다면 getMaxFrequency()의 반환 값은 None이 되어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8280cca",
   "metadata": {},
   "source": [
    "- 8) 임의의 단어 1개를 파라미터로 받는 searchUrlByWord() 메소드를 구현하여 유사도가 높은 웹 사이트를 출력하시오.   \n",
    "\n",
    ">\\>>> w1.searchUrlByWord(\"news\")<br>\n",
    "http://www.cnn.com<br>\n",
    "- 파라미터로 받은 단어와 유사도가 동일한 URL이 여러 개이면 해당 URL을 모두 출력하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce10ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0316384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # html 소스를 가져오기 위해 삽입\n",
    "import html # html escape 문자 변환을 위해 삽입\n",
    "import string # punctuation(구두문자) 제거를 위해 삽입\n",
    "\n",
    "class SearchEngine:\n",
    "    # 2. 생성자 인수를 가변인수로 정의\n",
    "    def __init__(self, *arg):\n",
    "        urlList = []\n",
    "        for e in arg:\n",
    "            urlList.append(e)\n",
    "        self.urlList = urlList # URL 리스트\n",
    "        self.wordDict = {}     # 단어와 출현 빈도수 사전\n",
    "        \n",
    "    # 3. addUrl() 메소드 구현\n",
    "    def addUrl(self, url):\n",
    "        if url not in self.urlList: # URL 중복 방지\n",
    "            self.urlList.append(url)    \n",
    "    \n",
    "    # 4. removeUrl() 메소드 구현\n",
    "    def removeUrl(self, url):\n",
    "        if url in self.urlList: # URL 값이 없는 경우 방지(ValueError)\n",
    "            self.urlList.remove(url)\n",
    "        \n",
    "    # 5. listUrl() 메소드 구현\n",
    "    def listUrls(self):\n",
    "        for url in self.urlList:\n",
    "            print(url)\n",
    "    \n",
    "    # 6. getWordsFrequency() 메소드 구현\n",
    "    def getWordsFrequency(self):\n",
    "        totalWordList = []       # 전체 URL 단어 리스트\n",
    "        wordList = []            # URL별 임시 단어 리스트\n",
    "        for url in self.urlList:\n",
    "            try:\n",
    "                source = \"\"\n",
    "                # 6.1 URL 소스 가져오기\n",
    "                # 6.1.1 사이트 주소 검사 1\n",
    "                req = requests.get(url, verify=True)  # html 소스 가져오기\n",
    "                                                       # https:// 사이트 소스를 가져올 때 SSLError 발생을 방지하고자\n",
    "                                                       # SSL 인증서 확인 과정 생략: (verify=False)\n",
    "                                                       # 학교 사이트 이외의 경우 문제없어서 (verify=True)로 설정\n",
    "                # 6.1.2 사이트 주소 검사 2\n",
    "                if req.status_code != requests.codes.ok: # raise_for_status()로 응답/요청 검사 \n",
    "                    print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\") # 사이트 주소가 틀린 경우\n",
    "                    print(\"에러코드: {}, 에러명: {}\".format(req.status_code, req.reason))\n",
    "                \n",
    "                # 6.1.3 소스 가져오기\n",
    "                source = req.text # .text는 encoding 속성을 이용해 바이트코드를 문자열로 디코딩한다.\n",
    "                                \n",
    "                # 6.1.4 인코딩이 Unicode, euc-kr 인지 검사\n",
    "                encodingValue = req.encoding # 인코딩값 가져와 저장\n",
    "                encodingValue = encodingValue.lower() # 대문자인 경우가 있으므로 소문자로 변환\n",
    "                if encodingValue != 'utf-8' and encodingValue != 'euc-kr': # 한글 인코딩이 아닌 경우\n",
    "                    source = html.unescape(source)  # 한글 인코딩이 아닌 경우 unescape로 문자를 변환한다.\n",
    "                else:\n",
    "                    source = source\n",
    "                               \n",
    "                # 6.2 순수 문자열 텍스트만 걸러내기 -> stringFilter() 함수\n",
    "                # 6.2.1 문자열 리스트 저장할 리스트 선언\n",
    "                #wordList = []\n",
    "\n",
    "                # 6.2.2 '<script ...> ~ </script>' 스크립트 태그 내용 제거\n",
    "                while((source.find('<script')+1) and (source.find('</script>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                     # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                     # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<script')\n",
    "                    lastIndex = source.find('</script>') + len('</script>') # '</script>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.3 '<style ...> ~ </style>' 스타일 태그 내용 제거\n",
    "                while((source.find('<style')+1) and (source.find('</style>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                   # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                   # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<style') \n",
    "                    lastIndex = source.find('</style>') + len('</style>') # '</style>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "               # 6.2.4 '<!--'로 시작해서 '-->' 주석 태그 제거, '->'와 같이 화살표 표시로 인해 에러 발생\n",
    "                while((source.find('<!--')+1) and (source.find('-->')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<!--')\n",
    "                    lastIndex = source.find('-->') + len('-->') # '-->' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "               # 6.2.5 '<url>'로 시작해서 '</url>' 끝나는 태그 제거, 특정 사이트에서 '<a href=\"<url> </url>\"> 문법 사용\n",
    "                while((source.find('<url>')+1) and (source.find('</url>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<url>')\n",
    "                    lastIndex = source.find('</url>') + len('</url>') # '</url>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "                # 6.2.6 '<'로 시작해서 '>' 끝나는 태그 제거\n",
    "                while((source.find('<')+1) and(source.find('>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "\n",
    "                    firstIndex = source.find('<')\n",
    "                    lastIndex = source.find('>') + len('>') # '>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.7 punctuation 구두문자 제거\n",
    "                punctlist = list(string.punctuation)\n",
    "                for punct in punctlist:\n",
    "                    source = source.replace(punct, '')\n",
    "\n",
    "                # 6.2.8 source를 리스트로 저장\n",
    "                wordList = source.split()\n",
    "                \n",
    "                # 6.2.9 전체 단어 저장\n",
    "                totalWordList = totalWordList + wordList\n",
    "                #global totalWordList = totalWordList\n",
    "                \n",
    "            except Exception as msg:\n",
    "                print(url)\n",
    "                print(msg)\n",
    "                print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\")\n",
    "                \n",
    "        # 6.2.9 필터링된 source 값 리스트 출력\n",
    "        #print(\"\\n1. 필터링된 source 값 리스트\\n\\n\", wordList)          \n",
    "\n",
    "        # 6.2.10 중복제거 전 단어의 개수\n",
    "        #print(\"\\n2. 중복제거 전 단어의 개수: {}개\\n\".format(len(wordList)))\n",
    "\n",
    "        # 6.3 출현빈도 수 계산 후 사전형태로 저장\n",
    "        # 6.3.1 각 단어들의 출현빈도수-> wordCount() 함수:\n",
    "        word_set = set(totalWordList) # 중복된 문자열 제거\n",
    "        keyList = list(word_set) # 키 목록 리스트화\n",
    "        wordDict = {}            # 사전 정의\n",
    "        for key in keyList:     # 키 목록만큼\n",
    "            value = totalWordList.count(key) # 단어 리스트에서 해당 키의 출현빈도 계산\n",
    "            wordDict[key] = value       # 해당 키와 출현빈도를 사전에 저장\n",
    "\n",
    "        # 6.3.2 각 단어들의 출현빈도수 출력\n",
    "        #print(\"3. 각 단어들의 출현빈도 수\\n\")\n",
    "        #print(wordDict)\n",
    "\n",
    "        # 6.3.3 중복제거 후 단어의 개수\n",
    "        #print(\"\\n4. 중복제거 후 단어의 개수: {}개\\n\".format(len(wordDict)))\n",
    "\n",
    "        # 6.4 불용어 필터링 -> stopWordRemove(wordDict) 함수\n",
    "        # 6.4.1 한글 불용어 필터링\n",
    "        # 6.4.1.1 한글 불용어 소스 가져오기 -> 사이트 검사과정 생략\n",
    "        url_stopWordKorean = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt'\n",
    "        req_stopWordKorean = requests.get(url_stopWordKorean, verify=True) # html 소스 가져오기\n",
    "        source_stopWordKorean = req_stopWordKorean.text\n",
    "\n",
    "        # 6.4.1.2 한글 불용어 제거\n",
    "        stopWordKorean = source_stopWordKorean.split('\\n')\n",
    "        for stopword in stopWordKorean:\n",
    "            for word in wordDict.keys():\n",
    "                if stopword == word:\n",
    "                    del wordDict[stopword]\n",
    "                    break\n",
    "\n",
    "        # 6.4.2 영문 불용어 필터링\n",
    "        # 6.4.2.1 영어 불용어 소스 가져오기 -> txt 파일에서\n",
    "        f = open('stop_words_english.txt', 'r', encoding='UTF8') # Encoding된 파일 열기 \n",
    "        stopWordEnglish = f.read()\n",
    "        stopWordEnglish = stopWordEnglish.split('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # 6.4.2.2 영어 불용어 제거\n",
    "        for stopword in stopWordEnglish:\n",
    "            for word in wordDict.keys():\n",
    "                if stopword == word:\n",
    "                    del wordDict[stopword]\n",
    "                    break\n",
    "\n",
    "        # 6.4.3 불용어 필터링 후 각 단어들의 출현빈도 수\n",
    "        #print(\"\\n5. 불용어 필터링 후 각 단어들의 출현빈도 수\\n\")\n",
    "        self.wordDict = wordDict\n",
    "        return self.wordDict\n",
    "        \n",
    "        # 6.4.4 불용어 필터링 후 단어의 개수\n",
    "        #print(\"\\n6. 불용어 필터링 후 단어의 개수: {}개\\n\".format(len(wordDict)))\n",
    "    \n",
    "    # 7. getMaxFrequencyWords() 메소드 구현\n",
    "    def getMaxFrequencyWords(self):\n",
    "        # 출현 빈도수 사전 가져오기\n",
    "        if len(self.wordDict) == 0:  # getWordsFrequency()가 한번도 실행되지 않았다면\n",
    "            self.getWordsFrequency() # getWordsFrequency()를 실행하여 출현 빈도수 사전 저장\n",
    "        \n",
    "        # 저장된 사전을 wordDict 변수에 초기화\n",
    "        wordDict = self.wordDict\n",
    "        \n",
    "        # 7.1 가장 많이 출현한 단어 찾기\n",
    "        # 7.1.1 최대 출현 빈도수 설정\n",
    "        maxValueDict = {}\n",
    "        if len(wordDict) > 0: # URL 리스트가 있는 경우\n",
    "            maxValue = list(wordDict.values())[0]\n",
    "            # 7.1.2 가장 많이 출현한 값의 빈도수 찾기\n",
    "            for value in wordDict.values():\n",
    "                if value > maxValue:\n",
    "                    maxValue = value\n",
    "\n",
    "            # 7.1.3 가장 많이 출현한 값과 빈도수를 사전에 저장\n",
    "            for key, value in wordDict.items():\n",
    "                if value == maxValue:\n",
    "                    maxValueDict[key] = value\n",
    "\n",
    "            return maxValueDict\n",
    "        else:                # URL 리스트가 없는 경우\n",
    "            return print(\"None\")\n",
    "        \n",
    "\n",
    "    \n",
    "    #8. searchUrlByWord() 메소드 구현\n",
    "    def searchUrlByWord(self, searchWord):\n",
    "        # 8.1 검색어 불용어 필터링 -> stopWordRemove(wordList) 함수\n",
    "        # 8.1.1 '' 공백을 기준으로 검색어를 리스트화\n",
    "        searchWordList = searchWord.split(' ')\n",
    "\n",
    "        # 8.1.2 한글 불용어 필터링\n",
    "        # 8.1.2.1 한글 불용어 소스 가져오기 -> 사이트 검사과정 생략\n",
    "        url_stopWordKorean = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt'\n",
    "        req_stopWordKorean = requests.get(url_stopWordKorean, verify=True) # html 소스 가져오기\n",
    "        source_stopWordKorean = req_stopWordKorean.text\n",
    "\n",
    "        # 8.1.2.2 한글 불용어 제거\n",
    "        stopWordKorean = source_stopWordKorean.split('\\n')\n",
    "        for stopword in stopWordKorean:\n",
    "            for word in searchWordList:\n",
    "                if stopword == word:\n",
    "                    searchWordList.remove(stopword)\n",
    "                    break\n",
    "\n",
    "        # 8.1.3 영어 불용어 필터링\n",
    "        # 8.1.3.1 영어 불용어 소스 가져오기 -> txt 파일에서\n",
    "        f = open('stop_words_english.txt', 'r', encoding='UTF8') # Encoding된 파일 열기 \n",
    "        stopWordEnglish = f.read()\n",
    "        stopWordEnglish = stopWordEnglish.split('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # 8.1.3.2 영어 불용어 제거\n",
    "        for stopword in stopWordEnglish:\n",
    "            for word in searchWordList:\n",
    "                if stopword == word:\n",
    "                    searchWordList.remove(stopword)\n",
    "                    break\n",
    "                    \n",
    "        # 8.1.4 리스트를 '' 구분자를 기준으로 다시 문자열화\n",
    "        searchWord = ' '.join(searchWordList)\n",
    "        \n",
    "        # 8.2 각 url 별로 wordDict를 만들고, 해당 단어가 있다면 검색 리스트에 추가 (url, key, value)\n",
    "        similarList = []      # 찾은 리스트\n",
    "        searchWordList = []   # 검색할 단어 리스트\n",
    "        wordList = []         # 사전에 단어 리스트\n",
    "        for url in self.urlList:\n",
    "            try:\n",
    "                source = \"\"\n",
    "                # 6.1 URL 소스 가져오기\n",
    "                # 6.1.1 사이트 주소 검사 1\n",
    "                req = requests.get(url, verify=True) # html 소스 가져오기\n",
    "                                                       # https:// 사이트 소스를 가져올 때 SSLError 발생을 방지하고자\n",
    "                                                       # SSL 인증서 확인 과정 생략(verify=False)\n",
    "                \n",
    "                # 6.1.2 사이트 주소 검사 2\n",
    "                if req.status_code != requests.codes.ok: # raise_for_status()로 응답/요청 검사 \n",
    "                    print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\") # 사이트 주소가 틀린 경우\n",
    "                    print(\"에러코드: {}, 에러명: {}\".format(req.status_code, req.reason))\n",
    "                \n",
    "                # 6.1.3 소스 가져오기\n",
    "                source = req.text # .text는 encoding 속성을 이용해 바이트코드를 문자열로 디코딩한다.\n",
    "                                \n",
    "                # 6.1.4 인코딩이 Unicode, euc-kr 인지 검사\n",
    "                encodingValue = req.encoding # 인코딩값 가져와 저장\n",
    "                encodingValue = encodingValue.lower() # 대문자인 경우가 있으므로 소문자로 변환\n",
    "                if encodingValue != 'utf-8' and encodingValue != 'euc-kr': # 한글 인코딩이 아닌 경우\n",
    "                    source = html.unescape(source)  # 한글 인코딩이 아닌 경우 unescape로 문자를 변환한다.\n",
    "                else:\n",
    "                    source = source\n",
    "                               \n",
    "                # 6.2 순수 문자열 텍스트만 걸러내기 -> stringFilter() 함수\n",
    "                # 6.2.1 문자열 리스트 저장할 리스트 선언\n",
    "                #wordList = []\n",
    "\n",
    "                # 6.2.2 '<script ...> ~ </script>' 스크립트 태그 내용 제거\n",
    "                while((source.find('<script')+1) and (source.find('</script>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                     # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                     # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<script')\n",
    "                    lastIndex = source.find('</script>') + len('</script>') # '</script>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.3 '<style ...> ~ </style>' 스타일 태그 내용 제거\n",
    "                while((source.find('<style')+1) and (source.find('</style>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                   # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                   # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<style') \n",
    "                    lastIndex = source.find('</style>') + len('</style>') # '</style>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "               # 6.2.4 '<!--'로 시작해서 '-->' 주석 태그 제거, '->'와 같이 화살표 표시로 인해 에러 발생\n",
    "                while((source.find('<!--')+1) and (source.find('-->')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<!--')\n",
    "                    lastIndex = source.find('-->') + len('-->') # '-->' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "               # 6.2.5 '<url>'로 시작해서 '</url>' 끝나는 태그 제거, 특정 사이트에서 '<a href=\"<url> </url>\"> 문법 사용\n",
    "                while((source.find('<url>')+1) and (source.find('</url>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<url>')\n",
    "                    lastIndex = source.find('</url>') + len('</url>') # '</url>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "                # 6.2.6 '<'로 시작해서 '>' 끝나는 태그 제거\n",
    "                while((source.find('<')+1) and(source.find('>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "\n",
    "                    firstIndex = source.find('<')\n",
    "                    lastIndex = source.find('>') + len('>') # '>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.7 punctuation 구두문자 제거\n",
    "                punctlist = list(string.punctuation)\n",
    "                for punct in punctlist:\n",
    "                    source = source.replace(punct, '')\n",
    "\n",
    "                # 6.2.8 source를 리스트로 저장\n",
    "                wordList = source.split()\n",
    "                \n",
    "                # 6.2.9 필터링된 source 값 리스트 출력\n",
    "                #print(\"\\n1. 필터링된 source 값 리스트\\n\\n\", wordList)          \n",
    "\n",
    "                # 6.2.10 중복제거 전 단어의 개수\n",
    "                #print(\"\\n2. 중복제거 전 단어의 개수: {}개\\n\".format(len(wordList)))\n",
    "\n",
    "                # 6.3 출현빈도 수 계산 후 사전형태로 저장\n",
    "                # 6.3.1 각 단어들의 출현빈도수-> wordCount() 함수:\n",
    "                word_set = set(wordList) # 중복된 문자열 제거\n",
    "                keyList = list(word_set) # 키 목록 리스트화\n",
    "                wordDict = {}            # 사전 정의\n",
    "                for key in keyList:     # 키 목록만큼\n",
    "                    value = wordList.count(key) # 단어 리스트에서 해당 키의 출현빈도 계산\n",
    "                    wordDict[key] = value       # 해당 키와 출현빈도를 사전에 저장\n",
    "\n",
    "                # 6.3.2 각 단어들의 출현빈도수 출력\n",
    "                #print(\"3. 각 단어들의 출현빈도 수\\n\")\n",
    "                #print(wordDict)\n",
    "\n",
    "                # 6.3.3 중복제거 후 단어의 개수\n",
    "                #print(\"\\n4. 중복제거 후 단어의 개수: {}개\\n\".format(len(wordDict)))\n",
    "\n",
    "                # 6.4 불용어 필터링 -> stopWordRemove(wordDict) 함수\n",
    "                # 6.4.1 한글 불용어 필터링\n",
    "                # 6.4.1.1 한글 불용어 소스 가져오기 -> 사이트 검사과정 생략\n",
    "                url_stopWordKorean = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt'\n",
    "                req_stopWordKorean = requests.get(url_stopWordKorean, verify=True) # html 소스 가져오기\n",
    "                source_stopWordKorean = req_stopWordKorean.text\n",
    "\n",
    "                # 6.4.1.2 한글 불용어 제거\n",
    "                stopWordKorean = source_stopWordKorean.split('\\n')\n",
    "                for stopword in stopWordKorean:\n",
    "                    for word in wordDict.keys():\n",
    "                        if stopword == word:\n",
    "                            del wordDict[stopword]\n",
    "                            break\n",
    "\n",
    "                # 6.4.2 영어 불용어 필터링\n",
    "                # 6.4.2.1 영어 불용어 소스 가져오기 -> txt 파일에서\n",
    "                f = open('stop_words_english.txt', 'r', encoding='UTF8') # Encoding된 파일 열기 \n",
    "                stopWordEnglish = f.read()\n",
    "                stopWordEnglish = stopWordEnglish.split('\\n')\n",
    "                f.close()\n",
    "\n",
    "                # 6.4.2.2 영어 불용어 제거\n",
    "                for stopword in stopWordEnglish:\n",
    "                    for word in wordDict.keys():\n",
    "                        if stopword == word:\n",
    "                            del wordDict[stopword]\n",
    "                            break\n",
    "\n",
    "                # 6.4.3 불용어 필터링 후 각 단어들의 출현빈도 수\n",
    "                #print(\"\\n5. 불용어 필터링 후 각 단어들의 출현빈도 수\\n\")\n",
    "                #return print(wordDict)\n",
    "\n",
    "                # 6.4.4 불용어 필터링 후 단어의 개수\n",
    "                #print(\"\\n6. 불용어 필터링 후 단어의 개수: {}개\\n\".format(len(wordDict)))  \n",
    "\n",
    "                #8.2 검색어를 url 사이트에서 찾아 출현빈도 리스트화하기\n",
    "                for word in wordDict.keys():\n",
    "                    if searchWord == word:\n",
    "                        similarList.append((url, word, wordDict[word]))\n",
    "               \n",
    "            except Exception as msg:\n",
    "                print(url)\n",
    "                print(msg)\n",
    "                print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\")\n",
    "                \n",
    "        # 8.3 출현빈도를 기준으로 내림차순 정렬하기\n",
    "        similarList = sorted(similarList, key = lambda value: value[2], reverse = True)\n",
    "\n",
    "        # 8.3 가장 높은 유사도의 검색 사이트 출력하기 \n",
    "        if len(similarList) == 0: # 검색된 사이트가 없는 경우\n",
    "            print(\"검색된 사이트가 없습니다.\\n\")\n",
    "        else: # 검색된 사이트가 있는 경우\n",
    "            similarMaxValue = similarList[0][2] # 최대 출현 빈도수 URL을 출력하기 위해 출현 빈도수 설정: 8.3에서 내림차순 했으므로\n",
    "                                                # 첫번째값이 가장 높은 출현 빈도수이다.\n",
    "            for index, valueList in enumerate(similarList, 1):\n",
    "                if valueList[2] == similarMaxValue:\n",
    "                    #print(\"사이트: {}, 출현빈도: {}\".format(valueList[0], valueList[2]))  # 출력 1: 사이트와 출현빈도수 출력\n",
    "                    print(\"{}\".format(valueList[0]))                                       # 출력 2: 사이트만 출력\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f0681df",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = SearchEngine('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com')\n",
    "w2 = SearchEngine('http://www.cnn.com', 'http://www.times.com')\n",
    "w3 = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "529cde67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.cnn.com\n",
      "http://www.times.com\n",
      "https://www.amazon.com\n",
      "https://github.com\n",
      "\n",
      "http://stackoverflow.com\n"
     ]
    }
   ],
   "source": [
    "# 3. addUrl() 메소드 테스트\n",
    "w1.addUrl('https://github.com')\n",
    "w3.addUrl('http://stackoverflow.com')\n",
    "\n",
    "w1.listUrls()\n",
    "print()\n",
    "w3.listUrls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "279639ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.times.com\n",
      "https://www.amazon.com\n",
      "https://github.com\n",
      "\n",
      "http://www.cnn.com\n",
      "http://www.times.com\n"
     ]
    }
   ],
   "source": [
    "#4. removeUrl() 메소드 테스트\n",
    "w1.removeUrl('http://www.cnn.com')\n",
    "w2.removeUrl('http://stackoverflow.com')\n",
    "\n",
    "w1.listUrls()\n",
    "print()\n",
    "w2.listUrls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eeb7d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.times.com\n",
      "https://www.amazon.com\n",
      "https://github.com\n",
      "\n",
      "http://www.cnn.com\n",
      "http://www.times.com\n",
      "\n",
      "http://stackoverflow.com\n"
     ]
    }
   ],
   "source": [
    "# 5. listUrl() 메소드 테스트\n",
    "w1.listUrls()\n",
    "print()\n",
    "w2.listUrls()\n",
    "print()\n",
    "w3.listUrls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e96716cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clued': 1,\n",
       " 'Arabic': 2,\n",
       " 'Get': 11,\n",
       " 'regulators': 1,\n",
       " 'Merto': 1,\n",
       " 'case': 1,\n",
       " 'sentence': 1,\n",
       " 'break': 2,\n",
       " 'Gets': 1,\n",
       " 'Debt': 1,\n",
       " 'mandatory': 1,\n",
       " 'Rekindle': 1,\n",
       " 'Economy': 2,\n",
       " 'We’re': 3,\n",
       " 'Facts': 2,\n",
       " 'criticized': 1,\n",
       " 'Features': 4,\n",
       " 'Schedule': 2,\n",
       " 'Holdover': 1,\n",
       " 'Continues': 1,\n",
       " 'Boom': 1,\n",
       " 'father': 1,\n",
       " 'Sufferer': 1,\n",
       " 'audience': 1,\n",
       " 'Mich': 2,\n",
       " 'Before': 1,\n",
       " 'Cottom': 1,\n",
       " 'movie': 1,\n",
       " 'Español': 3,\n",
       " 'Malosh': 2,\n",
       " 'Electric': 1,\n",
       " 'Freedom': 2,\n",
       " 'worried': 1,\n",
       " 'Meadows’s': 1,\n",
       " 'unusual': 1,\n",
       " 'Investigations': 2,\n",
       " 'years': 2,\n",
       " 'Prize': 1,\n",
       " 'Mission': 2,\n",
       " 'Times': 20,\n",
       " 'written': 1,\n",
       " 'Vehicle': 1,\n",
       " 'Ingber': 1,\n",
       " 'Change': 1,\n",
       " 'Sections': 1,\n",
       " 'Going': 1,\n",
       " 'heater': 1,\n",
       " 'strong': 1,\n",
       " 'Armando': 1,\n",
       " 'rising': 1,\n",
       " 'Reserved': 1,\n",
       " 'protection': 1,\n",
       " 'tourists': 1,\n",
       " 'Alexander': 1,\n",
       " 'Liberties': 1,\n",
       " 'Stay': 2,\n",
       " 'Apocalypse’': 1,\n",
       " 'Binge': 2,\n",
       " 'Gift': 1,\n",
       " 'Redefine': 1,\n",
       " 'Putin’s': 1,\n",
       " 'trip': 1,\n",
       " 'SchreiberAgence': 1,\n",
       " 'Wyden': 1,\n",
       " 'News': 11,\n",
       " 'Bezos': 1,\n",
       " 'Goes': 1,\n",
       " 'Americans': 1,\n",
       " 'London': 1,\n",
       " 'Elderly': 1,\n",
       " 'Inside': 2,\n",
       " 'History': 1,\n",
       " 'trophy': 1,\n",
       " 'leggings': 1,\n",
       " 'Abortion': 1,\n",
       " 'bags': 2,\n",
       " 'If': 7,\n",
       " 'ground': 1,\n",
       " 'Caron': 1,\n",
       " 'increases': 2,\n",
       " 'canvases': 1,\n",
       " 'soldiered': 1,\n",
       " 'Narrated': 1,\n",
       " 'ideas': 1,\n",
       " 'incarcerate': 1,\n",
       " 'economic': 1,\n",
       " 'Taxing': 1,\n",
       " 'Bob': 1,\n",
       " 'How': 16,\n",
       " 'Has': 1,\n",
       " 'Use': 1,\n",
       " 'Prosecutor': 1,\n",
       " 'illustrates': 1,\n",
       " 'sanitizer': 1,\n",
       " 'Worst': 1,\n",
       " 'While': 1,\n",
       " 'expert': 1,\n",
       " 'Food': 5,\n",
       " 'Prison': 1,\n",
       " 'Slavery': 1,\n",
       " 'What': 5,\n",
       " 'Coy': 2,\n",
       " 'Relationships': 2,\n",
       " 'Privacy': 2,\n",
       " 'T': 2,\n",
       " 'Anthony': 1,\n",
       " 'airport': 1,\n",
       " 'Nobel': 1,\n",
       " 'lines': 1,\n",
       " 'span': 1,\n",
       " 'succeed': 1,\n",
       " 'flying': 2,\n",
       " 'Félix': 1,\n",
       " 'US': 17,\n",
       " 'Police': 1,\n",
       " 'faces': 1,\n",
       " 'Style': 4,\n",
       " 'night': 1,\n",
       " 'Celebrating': 6,\n",
       " 'Ty': 1,\n",
       " '‘Improvise': 1,\n",
       " 'Fresh': 1,\n",
       " 'Stainless': 1,\n",
       " 'Are': 6,\n",
       " 'Mortals': 1,\n",
       " 'board': 1,\n",
       " 'Violence': 1,\n",
       " 'Presidency': 2,\n",
       " 'site': 2,\n",
       " 'Find': 1,\n",
       " 'Wired': 1,\n",
       " 'Gabriela': 1,\n",
       " '©': 3,\n",
       " 'Could': 2,\n",
       " 'Golf': 2,\n",
       " 'BlankenhornHBO': 1,\n",
       " 'Bears': 1,\n",
       " 'City”': 1,\n",
       " 'King': 1,\n",
       " 'Books': 1,\n",
       " 'USbound': 1,\n",
       " 'Wrong': 1,\n",
       " 'Senate': 1,\n",
       " 'KN95': 1,\n",
       " 'But': 4,\n",
       " 'Football': 2,\n",
       " 'Cooking': 1,\n",
       " 'Rip': 1,\n",
       " 'Supreme': 2,\n",
       " 'reactions': 1,\n",
       " 'Hester': 1,\n",
       " 'Rights': 1,\n",
       " 'Frijol': 1,\n",
       " 'friends': 2,\n",
       " 'tractortrailer': 1,\n",
       " 'America': 1,\n",
       " 'Architecture': 2,\n",
       " 'York': 23,\n",
       " 'HLN': 2,\n",
       " 'Jussie': 1,\n",
       " 'screening': 1,\n",
       " 'crammed': 1,\n",
       " 'Brain’': 1,\n",
       " '‘Dr': 1,\n",
       " 'experts': 2,\n",
       " 'Death': 1,\n",
       " 'Bean': 1,\n",
       " 'reading': 5,\n",
       " 'Mark': 3,\n",
       " 'releases': 1,\n",
       " 'Charged': 1,\n",
       " 'Gifts': 1,\n",
       " 'fleecelined': 1,\n",
       " 'Impact': 2,\n",
       " 'Efforts': 1,\n",
       " 'reused': 1,\n",
       " 'rows': 1,\n",
       " 'great': 1,\n",
       " 'Opinion': 2,\n",
       " 'Will': 1,\n",
       " 'AZ': 2,\n",
       " 'Despairing': 1,\n",
       " 'Salt': 1,\n",
       " 'we’d': 1,\n",
       " 'It’s': 1,\n",
       " 'Peter': 2,\n",
       " 'Vaccine': 2,\n",
       " 'Finish': 1,\n",
       " 'SomodevillaGetty': 1,\n",
       " 'ordered': 1,\n",
       " 'Gay': 1,\n",
       " 'Travel': 4,\n",
       " 'Honor’': 1,\n",
       " 'First': 2,\n",
       " 'claims': 1,\n",
       " 'Create': 1,\n",
       " 'planning': 2,\n",
       " 'boiled': 1,\n",
       " 'Briefing': 1,\n",
       " 'overwhelmed': 1,\n",
       " 'CNNVR': 2,\n",
       " 'Clarkson': 1,\n",
       " 'gather': 1,\n",
       " 'sell': 1,\n",
       " 'hot': 1,\n",
       " 'Easy': 1,\n",
       " 'Bartlett': 1,\n",
       " 'Than': 1,\n",
       " 'Roving': 1,\n",
       " 'Search': 3,\n",
       " 'Kelso': 1,\n",
       " 'Luxury': 2,\n",
       " 'What’s': 1,\n",
       " 'ordinary': 1,\n",
       " 'NYTCo': 1,\n",
       " 'Cole': 1,\n",
       " 'Innovate': 2,\n",
       " 'Maria': 1,\n",
       " 'effects': 1,\n",
       " 'feel': 1,\n",
       " 'Middle': 2,\n",
       " 'law': 1,\n",
       " 'meeting': 1,\n",
       " 'Me': 1,\n",
       " 'Lotus’': 1,\n",
       " 'industry': 1,\n",
       " 'Daily’': 1,\n",
       " 'Best': 1,\n",
       " 'Illustration': 1,\n",
       " 'Leaves': 1,\n",
       " 'Recommendations': 1,\n",
       " 'Mindfulness': 2,\n",
       " 'appears': 1,\n",
       " 'Man’': 1,\n",
       " 'Shooting': 1,\n",
       " 'NY': 1,\n",
       " 'Brooks': 1,\n",
       " 'Business': 4,\n",
       " 'McMillan': 1,\n",
       " 'Brenner': 1,\n",
       " 'My': 1,\n",
       " 'Different': 1,\n",
       " 'cut': 1,\n",
       " 'Mike': 1,\n",
       " 'Decombat': 1,\n",
       " '2021': 4,\n",
       " 'Complacency': 1,\n",
       " 'gathering': 1,\n",
       " 'Heroes': 2,\n",
       " 'young': 1,\n",
       " 'Ukraine': 1,\n",
       " 'Profiles': 2,\n",
       " 'Terms': 3,\n",
       " 'Ad': 2,\n",
       " '🎄': 1,\n",
       " 'don’t': 2,\n",
       " 'Any': 1,\n",
       " 'Oil': 1,\n",
       " '1308': 1,\n",
       " 'Ahead': 2,\n",
       " 'Allows': 1,\n",
       " 'Act': 1,\n",
       " 'Evening': 1,\n",
       " 'TaverniseNetflix': 1,\n",
       " '“Sex': 1,\n",
       " 'lawyer': 1,\n",
       " 'Murillo': 1,\n",
       " 'mask': 8,\n",
       " 'Holidays': 8,\n",
       " 'Take': 1,\n",
       " 'Fish': 1,\n",
       " 'attractive': 1,\n",
       " 'Exercise': 1,\n",
       " 'You': 5,\n",
       " 'Mr': 1,\n",
       " 'Oliver': 1,\n",
       " 'push': 1,\n",
       " 'Jancee': 1,\n",
       " 'Zeynep': 1,\n",
       " 'requirements': 1,\n",
       " 'Annies': 1,\n",
       " 'Oust': 1,\n",
       " 'Testa': 1,\n",
       " 'McDonald': 1,\n",
       " 'roll': 1,\n",
       " 'dishwasher': 1,\n",
       " 'Edition': 2,\n",
       " 'His': 1,\n",
       " 'Blum': 1,\n",
       " 'public': 3,\n",
       " 'family': 4,\n",
       " 'Europe': 2,\n",
       " 'Equals': 2,\n",
       " 'Getty': 4,\n",
       " 'Asia': 2,\n",
       " '✈️': 1,\n",
       " 'Coronavirus': 2,\n",
       " 'Brand': 1,\n",
       " 'So': 1,\n",
       " 'That’': 1,\n",
       " 'System': 1,\n",
       " 'Bank': 1,\n",
       " 'vaccinations': 4,\n",
       " 'Another': 1,\n",
       " 'Bars': 1,\n",
       " 'Cadavers’': 1,\n",
       " 'Upgrade': 1,\n",
       " 'Well': 2,\n",
       " 'Learn': 3,\n",
       " 'Wings': 1,\n",
       " 'Jelena': 1,\n",
       " 'Polls': 1,\n",
       " 'Corps': 1,\n",
       " 'Footage': 1,\n",
       " 'David': 5,\n",
       " 'space': 2,\n",
       " 'Elections': 2,\n",
       " '‘They': 1,\n",
       " 'Meadows': 1,\n",
       " 'Them': 1,\n",
       " 'lives': 1,\n",
       " 'Carnahan': 1,\n",
       " 'Us': 3,\n",
       " 'media': 1,\n",
       " 'guide': 3,\n",
       " 'Who': 1,\n",
       " 'frozen': 1,\n",
       " 'Service': 1,\n",
       " 'lastminute': 1,\n",
       " 'accessories': 1,\n",
       " 'Digital': 2,\n",
       " 'Public': 1,\n",
       " 'spaces': 1,\n",
       " 'A': 7,\n",
       " 'turn': 1,\n",
       " 'worn': 1,\n",
       " 'picking': 1,\n",
       " 'election': 2,\n",
       " 'Tony': 1,\n",
       " '2020': 3,\n",
       " 'disagree': 1,\n",
       " 'FrancePresse': 1,\n",
       " 'court': 2,\n",
       " 'undercut': 1,\n",
       " 'Oaxacan': 1,\n",
       " 'Ressa': 1,\n",
       " 'gift': 2,\n",
       " 'Rift': 1,\n",
       " 'Starting': 1,\n",
       " 'Tennis': 2,\n",
       " 'continues': 1,\n",
       " '‘Very': 1,\n",
       " 'Earbuds': 1,\n",
       " 'fundmanager': 1,\n",
       " 'Tiles': 1,\n",
       " 'reality': 2,\n",
       " 'festive': 1,\n",
       " '“infiltration”': 1,\n",
       " 'Yoko': 1,\n",
       " 'declare': 1,\n",
       " 'dilemma': 1,\n",
       " 'slammed': 1,\n",
       " 'Life': 4,\n",
       " 'narrated': 1,\n",
       " 'Minn': 2,\n",
       " '‘The': 2,\n",
       " 'suggestions': 1,\n",
       " 'Trust': 1,\n",
       " 'Having': 1,\n",
       " 'Gilbertson': 1,\n",
       " 'pace': 1,\n",
       " 'women': 1,\n",
       " 'SelfProclaimed': 1,\n",
       " 'Flawed': 1,\n",
       " 'Photos': 2,\n",
       " 'pressure': 1,\n",
       " 'funeral': 1,\n",
       " 'Newsletters': 3,\n",
       " 'paint': 1,\n",
       " 'Eulogizes': 1,\n",
       " 'Design': 2,\n",
       " 'Global': 2,\n",
       " 'response': 1,\n",
       " '40': 1,\n",
       " 'Tougher': 1,\n",
       " 'comfortable': 1,\n",
       " 'events': 1,\n",
       " 'County': 2,\n",
       " 'Pennsylvania': 1,\n",
       " 'Classics': 1,\n",
       " 'Dani': 1,\n",
       " 'grapple': 1,\n",
       " 'runner': 1,\n",
       " 'crisp': 1,\n",
       " 'chairwoman': 1,\n",
       " 'Dec': 1,\n",
       " 'Spectacle': 1,\n",
       " 'Vindman': 1,\n",
       " 'require': 2,\n",
       " 'Canada': 2,\n",
       " 'Awards': 1,\n",
       " 'Screen': 2,\n",
       " 'Grant': 1,\n",
       " 'confronted': 1,\n",
       " 'International': 5,\n",
       " 'safe': 1,\n",
       " 'Habit': 1,\n",
       " 'strikes': 1,\n",
       " 'Fierce': 1,\n",
       " 'days”': 1,\n",
       " '“only': 1,\n",
       " 'Seeking': 1,\n",
       " 'Milder': 1,\n",
       " 'gatherings': 2,\n",
       " 'Meltaways': 1,\n",
       " 'Studio': 1,\n",
       " 'Finance': 1,\n",
       " 'Great': 1,\n",
       " 'Lemon': 1,\n",
       " 'Longform': 2,\n",
       " 'B': 1,\n",
       " 'businesses': 1,\n",
       " 'letters': 2,\n",
       " 'Review': 1,\n",
       " 'detected': 2,\n",
       " 'list': 1,\n",
       " 'Subscriptions': 1,\n",
       " 'Then': 1,\n",
       " 'Try': 1,\n",
       " 'power': 1,\n",
       " 'Let': 1,\n",
       " 'Biden’s': 1,\n",
       " 'spots': 1,\n",
       " 'son': 1,\n",
       " 'Alex': 1,\n",
       " 'Revisit': 1,\n",
       " 'provide': 1,\n",
       " 'face': 1,\n",
       " 'patio': 1,\n",
       " 'Success': 2,\n",
       " '🆘': 1,\n",
       " 'friend': 1,\n",
       " 'Cool': 1,\n",
       " 'tax': 1,\n",
       " 'Wildfire': 2,\n",
       " 'walls': 1,\n",
       " '1m': 1,\n",
       " 'Scam': 1,\n",
       " 'Talks': 1,\n",
       " 'doesn’t': 1,\n",
       " 'Rafael': 1,\n",
       " 'images': 1,\n",
       " 'suggests': 1,\n",
       " 'January': 1,\n",
       " '80': 1,\n",
       " 'statute': 1,\n",
       " 'seemingly': 1,\n",
       " '™': 1,\n",
       " 'Hidden': 1,\n",
       " 'star': 1,\n",
       " 'honor': 1,\n",
       " 'Tressie': 1,\n",
       " 'Nothing': 2,\n",
       " 'Navigation': 1,\n",
       " 'Shucks': 1,\n",
       " 'abortions': 1,\n",
       " 'Plan': 1,\n",
       " 'Stew': 1,\n",
       " 'Artist’s': 1,\n",
       " 'United': 6,\n",
       " 'quality': 1,\n",
       " 'explain': 1,\n",
       " 'document': 1,\n",
       " '‘Quiet': 1,\n",
       " 'Covid': 1,\n",
       " 'Johnathon': 1,\n",
       " 'that’”': 1,\n",
       " 'Don’t': 1,\n",
       " 'Newsletter': 1,\n",
       " 'pushback': 1,\n",
       " 'Connect': 1,\n",
       " 'kind': 1,\n",
       " 'Baleaf': 1,\n",
       " 'We': 6,\n",
       " 'baseless': 1,\n",
       " '‘O’': 1,\n",
       " 'perfect': 1,\n",
       " 'Ghislaine': 1,\n",
       " 'bans': 2,\n",
       " 'Your': 4,\n",
       " 'Law': 1,\n",
       " 'Went': 1,\n",
       " 'Senator': 1,\n",
       " 'Craig': 1,\n",
       " 'square': 1,\n",
       " 'cozy': 1,\n",
       " '“We': 1,\n",
       " 'accomplish': 1,\n",
       " 'suicide': 1,\n",
       " 'Newsource': 1,\n",
       " 'Homes’': 1,\n",
       " 'Sports': 6,\n",
       " 'Become': 1,\n",
       " 'Modern': 1,\n",
       " 'mother': 1,\n",
       " 'trackers': 2,\n",
       " 'Esports': 2,\n",
       " 'September': 1,\n",
       " 'Monkee’': 1,\n",
       " 'Albums': 1,\n",
       " 'Washington': 3,\n",
       " 'Better': 3,\n",
       " 'Small': 3,\n",
       " 'Fitness': 2,\n",
       " 'I’ve': 1,\n",
       " 'Black': 1,\n",
       " 'surveys': 1,\n",
       " 'shielded': 1,\n",
       " 'cold': 1,\n",
       " 'tips': 1,\n",
       " 'picky': 1,\n",
       " 'delightful': 1,\n",
       " 'scientists': 1,\n",
       " 'Weigh': 1,\n",
       " 'Crumbley’s': 1,\n",
       " 'ParkerPope': 2,\n",
       " 'Samuel': 1,\n",
       " 'genres': 1,\n",
       " 'Address': 1,\n",
       " 'Bee': 1,\n",
       " 'chef': 1,\n",
       " 'Our': 1,\n",
       " 'Michael': 3,\n",
       " 'Election': 1,\n",
       " 'Tamales': 2,\n",
       " 'cloth': 1,\n",
       " 'option': 1,\n",
       " 'Victories': 1,\n",
       " 'Follow': 2,\n",
       " 'advice': 3,\n",
       " 'Sans': 1,\n",
       " 'Avg': 1,\n",
       " 'Stars': 2,\n",
       " 'Prepare': 1,\n",
       " 'Ono': 1,\n",
       " 'bunch': 1,\n",
       " 'Say': 1,\n",
       " 'Tokyo': 2,\n",
       " 'Statement': 1,\n",
       " 'Bigger': 1,\n",
       " 'participation': 1,\n",
       " 'Its': 2,\n",
       " 'refrigerated': 1,\n",
       " 'job': 1,\n",
       " 'Trump': 3,\n",
       " 'Beatles': 2,\n",
       " 'Markets': 2,\n",
       " 'unvaccinated': 2,\n",
       " 'highquality': 1,\n",
       " 'Friday': 1,\n",
       " 'Information': 1,\n",
       " 'Leadership': 2,\n",
       " 'emergency': 1,\n",
       " 'Be': 2,\n",
       " 'delivers': 1,\n",
       " 'Inflation': 2,\n",
       " 'double': 1,\n",
       " 'weeks': 2,\n",
       " 'Debate': 1,\n",
       " 'holidays': 3,\n",
       " 'nations': 1,\n",
       " 'He': 1,\n",
       " 'photograph': 1,\n",
       " 'painter': 1,\n",
       " 'Articles': 2,\n",
       " 'I’m': 2,\n",
       " 'puts': 1,\n",
       " 'Start': 1,\n",
       " 'drink': 1,\n",
       " 'silicone': 1,\n",
       " 'Entertainment': 3,\n",
       " 'Item': 1,\n",
       " 'nonpartisan': 1,\n",
       " 'Offenses': 1,\n",
       " 'Cable': 2,\n",
       " 'Stasher': 1,\n",
       " 'considers': 1,\n",
       " 'OK': 1,\n",
       " 'Guatemala': 1,\n",
       " 'Map': 1,\n",
       " 'Tufekci': 1,\n",
       " 'McWilliams': 1,\n",
       " 'one’s': 1,\n",
       " 'time': 3,\n",
       " 'lawsuit': 1,\n",
       " 'Maxwell': 1,\n",
       " 'pregnancy': 2,\n",
       " 'Reading': 1,\n",
       " 'growth': 1,\n",
       " 'Play': 1,\n",
       " 'Old': 1,\n",
       " 'Pistol': 1,\n",
       " 'Why': 4,\n",
       " 'prices': 1,\n",
       " 'together”': 1,\n",
       " 'Civil': 1,\n",
       " 'PilipeyEPA': 1,\n",
       " 'Barks': 1,\n",
       " 'Tiller': 1,\n",
       " 'Accessibility': 2,\n",
       " 'Sea': 1,\n",
       " 'Gadget': 2,\n",
       " 'review': 1,\n",
       " 'Science': 1,\n",
       " 'Evergrande': 1,\n",
       " 'And': 1,\n",
       " 'Dead': 1,\n",
       " 'CC': 1,\n",
       " 'Broccoli': 1,\n",
       " 'hold': 1,\n",
       " 'Reportedly': 1,\n",
       " 'Michigan': 1,\n",
       " 'season': 1,\n",
       " 'Fruity': 1,\n",
       " 'FAA': 1,\n",
       " 'Sarahbeth': 2,\n",
       " 'Nat': 1,\n",
       " 'Wirecutter’s': 1,\n",
       " 'China': 3,\n",
       " 'New': 28,\n",
       " 'Protests': 1,\n",
       " 'meals': 1,\n",
       " 'Like': 3,\n",
       " 'Murtaugh': 1,\n",
       " 'wordplay': 1,\n",
       " '78': 1,\n",
       " '→': 1,\n",
       " 'Industry': 1,\n",
       " 'Olive': 1,\n",
       " 'distance': 1,\n",
       " 'speeding': 1,\n",
       " 'NYC': 1,\n",
       " 'Defaults': 1,\n",
       " 'Vertex': 1,\n",
       " '»': 1,\n",
       " 'Member': 1,\n",
       " 'I’ll': 1,\n",
       " 'Shutterstock': 2,\n",
       " 'Bryson': 1,\n",
       " 'testing': 1,\n",
       " 'Zandi': 1,\n",
       " 'It': 6,\n",
       " 'Videos': 8,\n",
       " 'Studios': 2,\n",
       " 'Updates': 1,\n",
       " 'Mara': 1,\n",
       " 'Media': 5,\n",
       " 'Cities': 2,\n",
       " 'Migrant': 1,\n",
       " 'evade': 1,\n",
       " 'leaders': 1,\n",
       " 'crowds': 1,\n",
       " 'Astronaut': 1,\n",
       " 'White': 1,\n",
       " 'recommended': 1,\n",
       " 'Politics': 4,\n",
       " 'Paper': 1,\n",
       " 'From': 2,\n",
       " 'Work': 6,\n",
       " 'Choices': 2,\n",
       " 'Had': 2,\n",
       " 'Smollett': 1,\n",
       " 'After': 2,\n",
       " 'dots': 1,\n",
       " 'parties': 1,\n",
       " 'Foreseeable': 2,\n",
       " 'content': 2,\n",
       " '‘Boring': 1,\n",
       " 'Menu': 1,\n",
       " '🎉': 1,\n",
       " 'classconscious': 1,\n",
       " 'Guide': 1,\n",
       " 'Document': 1,\n",
       " 'putting': 1,\n",
       " 'national': 1,\n",
       " 'chairman': 1,\n",
       " 'Rests': 1,\n",
       " 'winter': 2,\n",
       " 'attic': 1,\n",
       " 'On': 2,\n",
       " 'Considered': 1,\n",
       " 'Live': 2,\n",
       " 'Lerman': 1,\n",
       " 'investigation': 1,\n",
       " 'Contreras': 1,\n",
       " 'main': 5,\n",
       " 'Hagen': 1,\n",
       " '😳': 1,\n",
       " 'Today’s': 1,\n",
       " 'Jersey': 2,\n",
       " 'Returns': 1,\n",
       " '‘Treeson’': 1,\n",
       " 'Primary': 1,\n",
       " 'Niko': 1,\n",
       " 'Game': 1,\n",
       " 'Original': 1,\n",
       " 'Chip': 1,\n",
       " 'Healthy': 1,\n",
       " 'Jeff': 1,\n",
       " 'Projectors': 1,\n",
       " 'E': 2,\n",
       " 'deaths': 1,\n",
       " 'Allow': 1,\n",
       " 'Hold': 1,\n",
       " 'Award': 1,\n",
       " 'upside': 1,\n",
       " 'microwaved': 1,\n",
       " 'Year’': 1,\n",
       " 'evening': 1,\n",
       " 'License': 1,\n",
       " 'Brooklyn': 1,\n",
       " 'link': 1,\n",
       " 'linked': 1,\n",
       " 'safely': 2,\n",
       " 'Asserting': 1,\n",
       " 'you’re': 3,\n",
       " 'GOP': 1,\n",
       " 'raised': 1,\n",
       " 'custom': 1,\n",
       " 'Boys': 1,\n",
       " '‘And': 1,\n",
       " 'Weather': 2,\n",
       " 'TV': 6,\n",
       " 'short': 3,\n",
       " 'Hurley': 1,\n",
       " 'Destinations': 2,\n",
       " 'Regulators': 1,\n",
       " 'As': 4,\n",
       " 'Tell': 1,\n",
       " 'pair': 1,\n",
       " 'hosting': 1,\n",
       " 'collars': 1,\n",
       " '10': 2,\n",
       " 'mandate': 1,\n",
       " 'FDIC’s': 1,\n",
       " 'kids': 1,\n",
       " 'KF94': 1,\n",
       " 'Here’s': 4,\n",
       " 'With': 3,\n",
       " 'Teach': 1,\n",
       " 'reveal': 1,\n",
       " 'Republicans': 1,\n",
       " 'Perdue': 1,\n",
       " 'Health': 4,\n",
       " 'picture': 2,\n",
       " 'Arts': 3,\n",
       " 'Real': 1,\n",
       " 'price': 1,\n",
       " 'National': 1,\n",
       " 'Break': 1,\n",
       " 'filed': 1,\n",
       " 'Trying': 1,\n",
       " 'usual': 1,\n",
       " 'Films': 2,\n",
       " 'isn’t': 1,\n",
       " 'story': 6,\n",
       " '38': 1,\n",
       " 'Now': 1,\n",
       " 'Transformed': 2,\n",
       " 'Anytime': 1,\n",
       " 'hidden': 1,\n",
       " 'visual': 1,\n",
       " 'Through': 10,\n",
       " 'Peng': 1,\n",
       " 'tennis': 1,\n",
       " 'Smoked': 1,\n",
       " 'fastest': 1,\n",
       " 'Need': 1,\n",
       " 'Upstarts': 2,\n",
       " 'Paul': 1,\n",
       " 'Pekosz': 1,\n",
       " 'Arrived': 1,\n",
       " '18': 1,\n",
       " 'Suspect’s': 1,\n",
       " 'vaccines': 1,\n",
       " 'sports': 1,\n",
       " 'evidence': 1,\n",
       " 'solicit': 1,\n",
       " 'Cathedral': 1,\n",
       " 'Project': 2,\n",
       " 'Mexico': 1,\n",
       " 'county': 2,\n",
       " 'Jung': 1,\n",
       " 'Kingdom': 2,\n",
       " 'thought': 1,\n",
       " 'Relax': 1,\n",
       " 'Jails': 1,\n",
       " 'One': 1,\n",
       " 'that’s': 1,\n",
       " 'John': 1,\n",
       " 'Wirecutter': 1,\n",
       " '›': 8,\n",
       " 'Lifestyle': 1,\n",
       " 'Lying': 1,\n",
       " 'Yann': 1,\n",
       " 'Andrew': 4,\n",
       " 'Several': 1,\n",
       " 'Continue': 5,\n",
       " 'collectors': 1,\n",
       " 'Magazine': 2,\n",
       " 'heated': 1,\n",
       " 'Living': 1,\n",
       " 'Press': 1,\n",
       " 'surgical': 1,\n",
       " 'Warner': 1,\n",
       " 'Nursing': 2,\n",
       " 'Culture': 4,\n",
       " 'Climbing': 2,\n",
       " 'Sensational': 1,\n",
       " 'Letter': 1,\n",
       " 'Court': 4,\n",
       " 'Difficult': 1,\n",
       " 'BokatLindell': 1,\n",
       " 'Over': 1,\n",
       " 'Myers': 1,\n",
       " 'Degrees': 2,\n",
       " 'All': 5,\n",
       " 'Steel': 1,\n",
       " 'France': 2,\n",
       " 'actor': 1,\n",
       " 'N95': 1,\n",
       " 'Williams': 1,\n",
       " 'Nick': 1,\n",
       " 'Look': 3,\n",
       " 'figure': 1,\n",
       " 'Deal': 1,\n",
       " 'SEARCH': 1,\n",
       " 'Biden': 6,\n",
       " 'Fashion': 2,\n",
       " 'CNN': 19,\n",
       " 'Accuser': 1,\n",
       " 'Ways': 1,\n",
       " 'Karen': 1,\n",
       " 'day': 2,\n",
       " 'Tech': 5,\n",
       " 'health': 1,\n",
       " 'Mandates': 1,\n",
       " 'Adam': 1,\n",
       " 'Die': 1,\n",
       " 'Lost': 1,\n",
       " 'Ron': 1,\n",
       " 'Getting': 2,\n",
       " 'Happening': 1,\n",
       " 'Just': 1,\n",
       " 'Skip': 3,\n",
       " 'Iconoclast': 1,\n",
       " 'Tara': 2,\n",
       " 'angry': 1,\n",
       " 'That': 3,\n",
       " 'Subdued': 1,\n",
       " 'reboot': 1,\n",
       " 'Down': 1,\n",
       " 'ManeyThe': 2,\n",
       " 'big': 1,\n",
       " 'Five': 1,\n",
       " '中文': 1,\n",
       " 'judge': 1,\n",
       " '120917': 1,\n",
       " 'Tips': 1,\n",
       " 'agenda': 1,\n",
       " 'Oyster': 1,\n",
       " 'Breaking': 2,\n",
       " 'trickier': 1,\n",
       " 'More': 4,\n",
       " 'Turns': 1,\n",
       " 'hedge': 1,\n",
       " 'Ethan': 1,\n",
       " 'migrants': 1,\n",
       " 'NH': 2,\n",
       " 'owner': 1,\n",
       " 'GM’s': 1,\n",
       " 'Gathering': 1,\n",
       " 'Sitemap': 1,\n",
       " '‘Hell': 1,\n",
       " 'Hanna': 1,\n",
       " 'divorce': 1,\n",
       " 'Samantha': 1,\n",
       " 'Ultrarich': 1,\n",
       " 'Doing': 1,\n",
       " 'Sublime': 1,\n",
       " 'Other': 3,\n",
       " 'Home': 3,\n",
       " 'concerned': 1,\n",
       " 'GutierrezAssociated': 1,\n",
       " 'Sent': 1,\n",
       " 'Boxed': 1,\n",
       " 'Site': 2,\n",
       " 'Match': 1,\n",
       " 'Abortions': 1,\n",
       " 'Ask': 1,\n",
       " 'Still': 1,\n",
       " 'brighter': 1,\n",
       " 'BhaskarThe': 1,\n",
       " 'President': 5,\n",
       " 'Prosecution': 1,\n",
       " 'plans': 1,\n",
       " 'evoked': 1,\n",
       " 'Motorsport': 2,\n",
       " 'Classes': 1,\n",
       " 'generations': 1,\n",
       " 'Between': 1,\n",
       " 'Son': 1,\n",
       " 'Roman': 1,\n",
       " 'Folk': 1,\n",
       " 'security': 1,\n",
       " 'Time': 1,\n",
       " 'Muscle': 1,\n",
       " 'Policy': 2,\n",
       " 'Gods': 1,\n",
       " 'illustration': 1,\n",
       " 'elements': 1,\n",
       " 'searching': 1,\n",
       " 'India': 2,\n",
       " 'Crash': 1,\n",
       " '2022': 1,\n",
       " 'Potter': 1,\n",
       " 'Disrupting': 1,\n",
       " 'China’s': 1,\n",
       " 'Yechan': 1,\n",
       " 'changed': 1,\n",
       " 'Would': 1,\n",
       " 'World': 9,\n",
       " 'Flatbreads': 1,\n",
       " 'Parents': 1,\n",
       " 'Were': 1,\n",
       " 'Oscar': 1,\n",
       " 'Accept': 1,\n",
       " 'For': 6,\n",
       " 'projects': 1,\n",
       " 'McQuade': 1,\n",
       " 'Truck': 1,\n",
       " 'This': 2,\n",
       " 'School': 1,\n",
       " 'Soon': 1,\n",
       " 'Advertisement': 5,\n",
       " 'Shuai': 1,\n",
       " 'it’s': 2,\n",
       " 'struggling': 1,\n",
       " 'commit': 1,\n",
       " 'Network': 2,\n",
       " 'Resilience': 1,\n",
       " 'Experts': 1,\n",
       " 'collect': 1,\n",
       " 'In': 2,\n",
       " 'Subscribers': 1,\n",
       " 'Analysis': 1,\n",
       " 'receive': 1,\n",
       " 'Again': 1,\n",
       " 'Jan': 1,\n",
       " 'Australia': 2,\n",
       " 'Americas': 2,\n",
       " 'Scrivani': 1,\n",
       " 'Years': 1,\n",
       " 'Open': 1,\n",
       " 'Kelly': 1,\n",
       " 'sturdy': 1,\n",
       " 'Crossword': 1,\n",
       " 'Women': 1,\n",
       " 'Images': 6,\n",
       " 'Christina': 1,\n",
       " 'abortion': 1,\n",
       " 'Echoing': 1,\n",
       " 'Perspectives': 2,\n",
       " '2016': 1,\n",
       " 'wrong': 1,\n",
       " 'Challenge': 2,\n",
       " 'offers': 1,\n",
       " 'Money': 1,\n",
       " 'suggestion': 1,\n",
       " 'The': 30,\n",
       " 'airplane': 1,\n",
       " 'agony': 1,\n",
       " 'reduced': 1,\n",
       " 'Tom': 1,\n",
       " 'About': 3,\n",
       " 'gains': 1,\n",
       " 'chain': 1,\n",
       " 'projector': 1,\n",
       " 'Pans': 1,\n",
       " 'EpoxydudeGetty': 1,\n",
       " 'Sign': 1,\n",
       " 'hand': 1,\n",
       " 'Magic': 1,\n",
       " 'Avoid': 1,\n",
       " 'Sentenced': 1,\n",
       " 'pet': 1,\n",
       " 'CorumEPA': 1,\n",
       " 'dispute': 1,\n",
       " 'Climate': 2,\n",
       " 'Is': 4,\n",
       " ...}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. getWordsFrequency() 메소드 테스트\n",
    "w2.getWordsFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0dc88e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 30}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. getMaxFrequencyWords() 메소드 테스트\n",
    "w2.getMaxFrequencyWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29ed3d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. getWordsFrequency() 메소드 테스트_URL이 없는 경우\n",
    "w3.removeUrl(\"http://stackoverflow.com\")\n",
    "w3.getWordsFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1a2d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 7. getMaxFrequencyWords() 메소드 테스트_URL이 없는 경우\n",
    "w3.getMaxFrequencyWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3485ebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.cnn.com\n"
     ]
    }
   ],
   "source": [
    "# 8. searchUrlByWord() 메소드 테스트\n",
    "w2.searchUrlByWord(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efe16a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084f3d9",
   "metadata": {},
   "source": [
    "#### 2. 위 1번 문제에서 정의한 SearchEngine 클래스를 상속하여 SearchEngineWithOrderedWebWords 클래스를 정의하고 슈퍼클래스에 정의된 getWordsFrequency() 메소드를 오버라이드하여 단어 출현 빈도를 내림차순으로 정렬하여 리스트로 출력하시오.\n",
    "- 리스트 내의 각 원소는 단어와 빈도를 쌍으로 지니는 튜플이다.\n",
    "- getWordFrequency() 메소드에 reverse 라는 인자를 만들고 true 또는 false를 인자로 받을 수 있도록 한다.\n",
    "    - reverse 인자의 디폴트 값은 false 이며, 기본적으로 내림차순으로 정렬한다.\n",
    "    - reverse 인자에 true를 넣으면 오름차순으로 정렬한다.\n",
    "    \n",
    ">\\>>> w4 = SearchEngineWithOrderedWebWords('http://www.times.com', 'https://www.amazon.com', 'https://github.com')<br>\n",
    ">\\>>> w4.getWordsFrequency()<br>\n",
    "[('site', 12), ('science', 11), ('hello', 8), ('world', 2), ('program', 1), ('python', 1)]<br>\n",
    ">\\>>> w4.getWordsFrequency(reverse=true)<br>\n",
    "[('program', 1), ('python', 1), ('world', 2), ('hello', 8), ('science', 11), ('site', 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5eb8e1",
   "metadata": {},
   "source": [
    "#### 3. 다음과 같은 코딩이 가능하도록 SearchEngineWithOrderedWebWords안에 반복자와 관련된 메소드를 추가하시오.   \n",
    ">\\>>> for i in w4:<br>\n",
    ">\\>>>         print(i)<br>\n",
    "('site', 12)<br>\n",
    "('science', 11)<br>\n",
    "('hello', 8)<br>\n",
    "('world', 2)<br>\n",
    "('program', 1)<br>\n",
    "('python', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1926ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngineWithOrderedWebWords(SearchEngine):\n",
    "    def __init__(self, *arg):\n",
    "        SearchEngine.__init__(self, *arg)\n",
    "        self.resultList = [] # 정렬된 단어와 출현빈도 리스트\n",
    "    \n",
    "    # 2. getWordFrequency() 메소드 오버라이딩\n",
    "    def getWordsFrequency(self, reverse = False):\n",
    "        totalWordList = [] # 전체 URL 단어 리스트\n",
    "        wordList = []      # 각 URL별 단어 리스트\n",
    "        for url in self.urlList:\n",
    "            try:\n",
    "                source = \"\"\n",
    "                # 6.1 URL 소스 가져오기\n",
    "                # 6.1.1 사이트 주소 검사 1\n",
    "                req = requests.get(url, verify=True) # html 소스 가져오기\n",
    "                                                       # https:// 사이트 소스를 가져올 때 SSLError 발생을 방지하고자\n",
    "                                                       # SSL 인증서 확인 과정 생략(verify=False)\n",
    "                \n",
    "                # 6.1.2 사이트 주소 검사 2\n",
    "                if req.status_code != requests.codes.ok: # raise_for_status()로 응답/요청 검사 \n",
    "                    print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\") # 사이트 주소가 틀린 경우\n",
    "                    print(\"에러코드: {}, 에러명: {}\".format(req.status_code, req.reason))\n",
    "                \n",
    "                # 6.1.3 소스 가져오기\n",
    "                source = req.text # .text는 encoding 속성을 이용해 바이트코드를 문자열로 디코딩한다.\n",
    "                                \n",
    "                # 6.1.4 인코딩이 Unicode, euc-kr 인지 검사\n",
    "                encodingValue = req.encoding # 인코딩값 가져와 저장\n",
    "                encodingValue = encodingValue.lower() # 대문자인 경우가 있으므로 소문자로 변환\n",
    "                if encodingValue != 'utf-8' and encodingValue != 'euc-kr': # 한글 인코딩이 아닌 경우\n",
    "                    source = html.unescape(source)  # 한글 인코딩이 아닌 경우 unescape로 문자를 변환한다.\n",
    "                else:\n",
    "                    source = source\n",
    "                               \n",
    "                # 6.2 순수 문자열 텍스트만 걸러내기 -> stringFilter() 함수\n",
    "                # 6.2.1 문자열 리스트 저장할 사전 선언\n",
    "                #wordList = []\n",
    "\n",
    "                # 6.2.2 '<script ...> ~ </script>' 스크립트 태그 내용 제거\n",
    "                while((source.find('<script')+1) and (source.find('</script>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                     # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                     # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<script')\n",
    "                    lastIndex = source.find('</script>') + len('</script>') # '</script>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.3 '<style ...> ~ </style>' 스타일 태그 내용 제거\n",
    "                while((source.find('<style')+1) and (source.find('</style>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                                   # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                                   # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<style') \n",
    "                    lastIndex = source.find('</style>') + len('</style>') # '</style>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "               # 6.2.4 '<!--'로 시작해서 '-->' 주석 태그 제거, '->'와 같이 화살표 표시로 인해 에러 발생\n",
    "                while((source.find('<!--')+1) and (source.find('-->')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<!--')\n",
    "                    lastIndex = source.find('-->') + len('-->') # '-->' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "               # 6.2.5 '<url>'로 시작해서 '</url>' 끝나는 태그 제거, 특정 사이트에서 '<a href=\"<url> </url>\"> 문법 사용\n",
    "                while((source.find('<url>')+1) and (source.find('</url>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "                    firstIndex = source.find('<url>')\n",
    "                    lastIndex = source.find('</url>') + len('</url>') # '</url>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')    \n",
    "\n",
    "                # 6.2.6 '<'로 시작해서 '>' 끝나는 태그 제거\n",
    "                while((source.find('<')+1) and(source.find('>')+1)): # 문자열.find()시 값이 없으면 -1이므로 True다.\n",
    "                                                                       # 따라서 이 때 while()문 중단을 위해 +1을 하여\n",
    "                                                                       # 값을 0으로 만들어 False를 통해 중단시킨다.\n",
    "\n",
    "                    firstIndex = source.find('<')\n",
    "                    lastIndex = source.find('>') + len('>') # '>' 까지 제거해야 하므로\n",
    "                    source = source.replace(source[firstIndex:lastIndex], ' ')\n",
    "\n",
    "                # 6.2.7 punctuation 구두문자 제거\n",
    "                punctlist = list(string.punctuation)\n",
    "                for punct in punctlist:\n",
    "                    source = source.replace(punct, '')\n",
    "\n",
    "                # 6.2.8 source를 리스트로 저장\n",
    "                wordList = source.split()\n",
    "                \n",
    "                # 6.2.9 전체 단어 저장\n",
    "                totalWordList = totalWordList + wordList\n",
    "                \n",
    "            except Exception as msg:\n",
    "                print(url)\n",
    "                print(msg)\n",
    "                print(\"사이트 주소가 잘못되었습니다. 확인해주세요.\")\n",
    "                \n",
    "        # 6.2.9 필터링된 source 값 리스트 출력\n",
    "        #print(\"\\n1. 필터링된 source 값 리스트\\n\\n\", wordList)          \n",
    "\n",
    "        # 6.2.10 중복제거 전 단어의 개수\n",
    "        #print(\"\\n2. 중복제거 전 단어의 개수: {}개\\n\".format(len(wordList)))\n",
    "\n",
    "        # 6.3 출현빈도 수 계산 후 사전형태로 저장\n",
    "        # 6.3.1 각 단어들의 출현빈도수-> wordCount() 함수:\n",
    "        word_set = set(totalWordList) # 중복된 문자열 제거\n",
    "        keyList = list(word_set) # 키 목록 리스트화\n",
    "        wordDict = {}            # 사전 정의\n",
    "        for key in keyList:     # 키 목록만큼\n",
    "            value = totalWordList.count(key) # 단어 리스트에서 해당 키의 출현빈도 계산\n",
    "            wordDict[key] = value       # 해당 키와 출현빈도를 사전에 저장\n",
    "\n",
    "        # 6.3.2 각 단어들의 출현빈도수 출력\n",
    "        #print(\"3. 각 단어들의 출현빈도 수\\n\")\n",
    "        #print(wordDict)\n",
    "\n",
    "        # 6.3.3 중복제거 후 단어의 개수\n",
    "        #print(\"\\n4. 중복제거 후 단어의 개수: {}개\\n\".format(len(wordDict)))\n",
    "\n",
    "        # 6.4 불용어 필터링 -> stopWordRemove(wordDict) 함수\n",
    "        # 6.4.1 한글 불용어 필터링\n",
    "        # 6.4.1.1 한글 불용어 소스 가져오기 -> 사이트 검사과정 생략\n",
    "        url_stopWordKorean = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt'\n",
    "        req_stopWordKorean = requests.get(url_stopWordKorean, verify=True) # html 소스 가져오기\n",
    "        source_stopWordKorean = req_stopWordKorean.text\n",
    "\n",
    "        # 6.4.1.2 한글 불용어 제거\n",
    "        stopWordKorean = source_stopWordKorean.split('\\n')\n",
    "        for stopword in stopWordKorean:\n",
    "            for word in wordDict.keys():\n",
    "                if stopword == word:\n",
    "                    del wordDict[stopword]\n",
    "                    break\n",
    "\n",
    "        # 6.4.2 영어 불용어 필터링\n",
    "        # 6.4.2.1 영어 불용어 소스 가져오기 -> txt 파일에서\n",
    "        f = open('stop_words_english.txt', 'r', encoding='UTF8') # Encoding된 파일 열기 \n",
    "        stopWordEnglish = f.read()\n",
    "        stopWordEnglish = stopWordEnglish.split('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # 6.4.2.2 영어 불용어 제거\n",
    "        for stopword in stopWordEnglish:\n",
    "            for word in wordDict.keys():\n",
    "                if stopword == word:\n",
    "                    del wordDict[stopword]\n",
    "                    break\n",
    "\n",
    "        # 사전에서 출현빈도 수에 따른 오름차순/내림차순 구현\n",
    "        # 본래 True: 내림차순, False: 오름차순이나 문제에서 반대로 적용을 요구하므로 아래와 같이 조건문을 작성함\n",
    "        orderValue = reverse\n",
    "        if orderValue == False: # False 입력서 True로 값 변경\n",
    "            orderValue = True\n",
    "        else:                   # True 입력시 False로 값 변경\n",
    "            orderValue = False\n",
    "        resultList = sorted(wordDict.items(), key = lambda value: value[1], reverse = orderValue)\n",
    "        self.resultList = resultList\n",
    "        return resultList\n",
    "    \n",
    "    # 3. 반복자 관련 메소드 추가\n",
    "    def __iter__(self):\n",
    "        if len(self.resultList) == 0: # getWordsFrequency()가 한번도 실행안된 적이 없어, 리스트가 빈 경우\n",
    "            self.getWordsFrequency()  # getWordsFrequency() 실행\n",
    "        return iter(self.resultList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf996697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SearchEngine 클래스 상속 및 getWordsFrequency() 메소드 오버라이딩 테스트\n",
    "w6 = SearchEngineWithOrderedWebWords('http://www.cnn.com', 'http://www.times.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3ce2f2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 31), ('New', 28), ('York', 23), ('Times', 20), ('CNN', 19), ('US', 17), ('How', 16), ('Get', 11), ('News', 11), ('Through', 9), ('World', 9), ('mask', 8), ('Holidays', 8), ('A', 8), ('Videos', 8), ('›', 8), ('If', 7), ('Omicron', 7), ('Celebrating', 6), ('Are', 6), ('United', 6), ('We', 6), ('Sports', 6), ('It', 6), ('Work', 6), ('TV', 6), ('story', 6), ('Biden', 6), ('For', 6), ('Images', 6), ('Video', 6), ('Food', 5), ('What', 5), ('reading', 5), ('You', 5), ('David', 5), ('International', 5), ('Media', 5), ('main', 5), ('Continue', 5), ('All', 5), ('Tech', 5), ('President', 5), ('Advertisement', 5), ('Is', 5), ('Can', 5), ('Features', 4), ('Style', 4), ('But', 4), ('Travel', 4), ('Business', 4), ('2021', 4), ('family', 4), ('Getty', 4), ('vaccinations', 4), ('Life', 4), ('Your', 4), ('Why', 4), ('Politics', 4), ('As', 4), ('Here’s', 4), ('Health', 4), ('Andrew', 4), ('Culture', 4), ('Court', 4), ('More', 4), ('About', 4), ('Africa', 4), ('Tracker', 4), ('States', 4), ('case', 3), ('We’re', 3), ('Español', 3), ('©', 3), ('Mark', 3), ('Search', 3), ('Terms', 3), ('public', 3), ('Learn', 3), ('Us', 3), ('guide', 3), ('2020', 3), ('Newsletters', 3), ('Washington', 3), ('Better', 3), ('Small', 3), ('Michael', 3), ('advice', 3), ('Trump', 3), ('holidays', 3), ('Entertainment', 3), ('time', 3), ('China', 3), ('Like', 3), ('Live', 3), ('you’re', 3), ('short', 3), ('With', 3), ('Arts', 3), ('Look', 3), ('Skip', 3), ('That', 3), ('Other', 3), ('Home', 3), ('Tracking', 3), ('Do', 3), ('UK', 3), ('social', 3), ('Habits', 3), ('Holiday', 3), ('Shows', 3), ('Where', 3), ('Texas', 3), ('Make', 3), ('Arabic', 2), ('break', 2), ('Economy', 2), ('Facts', 2), ('Schedule', 2), ('Mich', 2), ('Malosh', 2), ('Freedom', 2), ('Investigations', 2), ('years', 2), ('Mission', 2), ('Stay', 2), ('Binge', 2), ('Inside', 2), ('bags', 2), ('increases', 2), ('Coy', 2), ('Relationships', 2), ('Privacy', 2), ('T', 2), ('Was', 2), ('flying', 2), ('Presidency', 2), ('site', 2), ('Could', 2), ('Golf', 2), ('Football', 2), ('Supreme', 2), ('friends', 2), ('Architecture', 2), ('HLN', 2), ('experts', 2), ('Impact', 2), ('Opinion', 2), ('AZ', 2), ('Peter', 2), ('Vaccine', 2), ('First', 2), ('planning', 2), ('CNNVR', 2), ('Luxury', 2), ('Innovate', 2), ('Middle', 2), ('Mindfulness', 2), ('Heroes', 2), ('Profiles', 2), ('Ad', 2), ('don’t', 2), ('Ahead', 2), ('Edition', 2), ('Europe', 2), ('Equals', 2), ('Asia', 2), ('Coronavirus', 2), ('Bars', 2), ('Well', 2), ('space', 2), ('Elections', 2), ('Digital', 2), ('election', 2), ('court', 2), ('gift', 2), ('Tennis', 2), ('reality', 2), ('Minn', 2), ('‘The', 2), ('Photos', 2), ('Design', 2), ('Global', 2), ('County', 2), ('require', 2), ('Canada', 2), ('Screen', 2), ('gatherings', 2), ('Great', 2), ('Longform', 2), ('letters', 2), ('detected', 2), ('Success', 2), ('Wildfire', 2), ('Nothing', 2), ('bans', 2), ('trackers', 2), ('Esports', 2), ('Fitness', 2), ('ParkerPope', 2), ('Tamales', 2), ('Follow', 2), ('Stars', 2), ('Tokyo', 2), ('Its', 2), ('Beatles', 2), ('Markets', 2), ('unvaccinated', 2), ('Leadership', 2), ('Be', 2), ('Inflation', 2), ('weeks', 2), ('Articles', 2), ('I’m', 2), ('Cable', 2), ('pregnancy', 2), ('Accessibility', 2), ('Gadget', 2), ('Sarahbeth', 2), ('Shutterstock', 2), ('Studios', 2), ('Cities', 2), ('From', 2), ('Choices', 2), ('Had', 2), ('After', 2), ('Foreseeable', 2), ('content', 2), ('winter', 2), ('On', 2), ('Jersey', 2), ('E', 2), ('safely', 2), ('Weather', 2), ('Destinations', 2), ('10', 2), ('picture', 2), ('Films', 2), ('Transformed', 2), ('Upstarts', 2), ('Project', 2), ('county', 2), ('Kingdom', 2), ('Magazine', 2), ('Nursing', 2), ('Climbing', 2), ('Degrees', 2), ('France', 2), ('Fashion', 2), ('day', 2), ('Getting', 2), ('Tara', 2), ('ManeyThe', 2), ('Breaking', 2), ('NH', 2), ('Site', 2), ('Motorsport', 2), ('Policy', 2), ('India', 2), ('This', 2), ('it’s', 2), ('Network', 2), ('In', 2), ('Australia', 2), ('Americas', 2), ('Perspectives', 2), ('Challenge', 2), ('Climate', 2), ('Innovative', 2), ('Future', 2), ('eat', 2), ('Give', 2), ('long', 2), ('Company', 2), ('decision', 2), ('Earth', 2), ('holiday', 2), ('Clean', 2), ('Listen', 2), ('Call', 2), ('Committee', 2), ('Sleep', 2), ('Advertise', 2), ('Storm', 2), ('pandemic', 2), ('Formula', 2), ('Photo', 2), ('Beauty', 2), ('Drink', 2), ('East', 2), ('clued', 1), ('Questions', 1), ('regulators', 1), ('Merto', 1), ('sentence', 1), ('Gets', 1), ('Debt', 1), ('mandatory', 1), ('Rekindle', 1), ('criticized', 1), ('Holdover', 1), ('Continues', 1), ('Boom', 1), ('father', 1), ('Sufferer', 1), ('audience', 1), ('Before', 1), ('Cottom', 1), ('movie', 1), ('Electric', 1), ('worried', 1), ('Meadows’s', 1), ('unusual', 1), ('Prize', 1), ('written', 1), ('Vehicle', 1), ('Ingber', 1), ('Change', 1), ('Sections', 1), ('Going', 1), ('heater', 1), ('strong', 1), ('Armando', 1), ('rising', 1), ('Reserved', 1), ('protection', 1), ('tourists', 1), ('Alexander', 1), ('Liberties', 1), ('Apocalypse’', 1), ('Gift', 1), ('Redefine', 1), ('Putin’s', 1), ('trip', 1), ('SchreiberAgence', 1), ('Wyden', 1), ('Bezos', 1), ('Goes', 1), ('Hits', 1), ('Americans', 1), ('London', 1), ('Elderly', 1), ('involved', 1), ('History', 1), ('trophy', 1), ('leggings', 1), ('Abortion', 1), ('ground', 1), ('Caron', 1), ('canvases', 1), ('soldiered', 1), ('Narrated', 1), ('ideas', 1), ('incarcerate', 1), ('economic', 1), ('Taxing', 1), ('Bob', 1), ('Has', 1), ('Use', 1), ('Prosecutor', 1), ('illustrates', 1), ('sanitizer', 1), ('Worst', 1), ('While', 1), ('expert', 1), ('Justice', 1), ('Prison', 1), ('Slavery', 1), ('Anthony', 1), ('airport', 1), ('Nobel', 1), ('lines', 1), ('span', 1), ('succeed', 1), ('Félix', 1), ('Police', 1), ('faces', 1), ('night', 1), ('Ty', 1), ('‘Improvise', 1), ('Fresh', 1), ('Stainless', 1), ('Mortals', 1), ('board', 1), ('Violence', 1), ('Find', 1), ('Wired', 1), ('Gabriela', 1), ('BlankenhornHBO', 1), ('Bears', 1), ('City”', 1), ('King', 1), ('Books', 1), ('USbound', 1), ('Wrong', 1), ('Senate', 1), ('KN95', 1), ('Cooking', 1), ('reactions', 1), ('Hester', 1), ('Rights', 1), ('Frijol', 1), ('tractortrailer', 1), ('Least', 1), ('America', 1), ('Jussie', 1), ('screening', 1), ('crammed', 1), ('Brain’', 1), ('‘Dr', 1), ('Death', 1), ('Bean', 1), ('releases', 1), ('Charged', 1), ('Gifts', 1), ('fleecelined', 1), ('Efforts', 1), ('reused', 1), ('committed', 1), ('rows', 1), ('great', 1), ('Will', 1), ('Despairing', 1), ('Gold', 1), ('Salt', 1), ('we’d', 1), ('It’s', 1), ('Finish', 1), ('SomodevillaGetty', 1), ('ordered', 1), ('Gay', 1), ('Honor’', 1), ('claims', 1), ('Create', 1), ('boiled', 1), ('Briefing', 1), ('overwhelmed', 1), ('Clarkson', 1), ('gather', 1), ('sell', 1), ('hot', 1), ('Easy', 1), ('Bartlett', 1), ('Than', 1), ('Roving', 1), ('Kelso', 1), ('What’s', 1), ('ordinary', 1), ('NYTCo', 1), ('Cole', 1), ('Maria', 1), ('effects', 1), ('feel', 1), ('law', 1), ('meeting', 1), ('Me', 1), ('Lotus’', 1), ('industry', 1), ('Daily’', 1), ('Best', 1), ('Illustration', 1), ('Leaves', 1), ('Recommendations', 1), ('appears', 1), ('Man’', 1), ('Shooting', 1), ('NY', 1), ('Brooks', 1), ('McMillan', 1), ('Brenner', 1), ('My', 1), ('Different', 1), ('cut', 1), ('Mike', 1), ('Decombat', 1), ('Complacency', 1), ('gathering', 1), ('young', 1), ('Ukraine', 1), ('🎄', 1), ('Any', 1), ('Oil', 1), ('1308', 1), ('Allows', 1), ('Act', 1), ('Evening', 1), ('TaverniseNetflix', 1), ('“Sex', 1), ('lawyer', 1), ('Murillo', 1), ('Take', 1), ('Fish', 1), ('attractive', 1), ('Exercise', 1), ('Mr', 1), ('Oliver', 1), ('push', 1), ('Jancee', 1), ('Zeynep', 1), ('requirements', 1), ('Annies', 1), ('Oust', 1), ('Testa', 1), ('McDonald', 1), ('roll', 1), ('dishwasher', 1), ('His', 1), ('Blum', 1), ('✈️', 1), ('Brand', 1), ('So', 1), ('That’', 1), ('System', 1), ('Bank', 1), ('Another', 1), ('Cadavers’', 1), ('Upgrade', 1), ('Wings', 1), ('Jelena', 1), ('Polls', 1), ('Corps', 1), ('Footage', 1), ('‘They', 1), ('Meadows', 1), ('Them', 1), ('lives', 1), ('Carnahan', 1), ('media', 1), ('Who', 1), ('frozen', 1), ('Service', 1), ('lastminute', 1), ('accessories', 1), ('Public', 1), ('spaces', 1), ('turn', 1), ('worn', 1), ('picking', 1), ('Tony', 1), ('disagree', 1), ('FrancePresse', 1), ('straightforward', 1), ('undercut', 1), ('Oaxacan', 1), ('Ressa', 1), ('Rift', 1), ('Starting', 1), ('continues', 1), ('‘Very', 1), ('Earbuds', 1), ('fundmanager', 1), ('Tiles', 1), ('festive', 1), ('“infiltration”', 1), ('Yoko', 1), ('declare', 1), ('dilemma', 1), ('slammed', 1), ('narrated', 1), ('suggestions', 1), ('Trust', 1), ('Having', 1), ('Gilbertson', 1), ('pace', 1), ('1993', 1), ('women', 1), ('SelfProclaimed', 1), ('Flawed', 1), ('pressure', 1), ('funeral', 1), ('paint', 1), ('Eulogizes', 1), ('response', 1), ('40', 1), ('Tougher', 1), ('comfortable', 1), ('events', 1), ('Pennsylvania', 1), ('Classics', 1), ('Dani', 1), ('grapple', 1), ('runner', 1), ('crisp', 1), ('chairwoman', 1), ('Dec', 1), ('Spectacle', 1), ('Vindman', 1), ('Awards', 1), ('Grant', 1), ('confronted', 1), ('safe', 1), ('Habit', 1), ('strikes', 1), ('Fierce', 1), ('days”', 1), ('“only', 1), ('Seeking', 1), ('Milder', 1), ('Meltaways', 1), ('Studio', 1), ('Finance', 1), ('murder', 1), ('Lemon', 1), ('B', 1), ('businesses', 1), ('Review', 1), ('list', 1), ('Subscriptions', 1), ('Then', 1), ('Try', 1), ('power', 1), ('Let', 1), ('Biden’s', 1), ('spots', 1), ('killing', 1), ('son', 1), ('Alex', 1), ('Revisit', 1), ('provide', 1), ('face', 1), ('patio', 1), ('🆘', 1), ('friend', 1), ('Cool', 1), ('tax', 1), ('walls', 1), ('1m', 1), ('Scam', 1), ('Talks', 1), ('doesn’t', 1), ('Rafael', 1), ('images', 1), ('suggests', 1), ('January', 1), ('80', 1), ('statute', 1), ('seemingly', 1), ('™', 1), ('Hidden', 1), ('star', 1), ('honor', 1), ('Tressie', 1), ('Navigation', 1), ('Shucks', 1), ('abortions', 1), ('Plan', 1), ('Stew', 1), ('Artist’s', 1), ('quality', 1), ('explain', 1), ('document', 1), ('‘Quiet', 1), ('Covid', 1), ('Johnathon', 1), ('that’”', 1), ('Don’t', 1), ('Newsletter', 1), ('pushback', 1), ('Connect', 1), ('kind', 1), ('Baleaf', 1), ('baseless', 1), ('‘O’', 1), ('perfect', 1), ('Ghislaine', 1), ('Law', 1), ('Went', 1), ('Senator', 1), ('Craig', 1), ('square', 1), ('cozy', 1), ('“We', 1), ('accomplish', 1), ('suicide', 1), ('Newsource', 1), ('Homes’', 1), ('Become', 1), ('Modern', 1), ('mother', 1), ('September', 1), ('Monkee’', 1), ('Albums', 1), ('1h', 1), ('I’ve', 1), ('Black', 1), ('surveys', 1), ('shielded', 1), ('cold', 1), ('tips', 1), ('picky', 1), ('delightful', 1), ('scientists', 1), ('Weigh', 1), ('Crumbley’s', 1), ('Samuel', 1), ('genres', 1), ('Address', 1), ('Bee', 1), ('chef', 1), ('Our', 1), ('Election', 1), ('cloth', 1), ('option', 1), ('Victories', 1), ('Tornado', 1), ('Sans', 1), ('Avg', 1), ('Prepare', 1), ('Ono', 1), ('bunch', 1), ('Say', 1), ('Jailbreak', 1), ('Statement', 1), ('Bigger', 1), ('participation', 1), ('refrigerated', 1), ('job', 1), ('highquality', 1), ('Friday', 1), ('Information', 1), ('emergency', 1), ('delivers', 1), ('double', 1), ('Debate', 1), ('nations', 1), ('He', 1), ('photograph', 1), ('painter', 1), ('puts', 1), ('Start', 1), ('drink', 1), ('silicone', 1), ('Item', 1), ('nonpartisan', 1), ('Offenses', 1), ('Stasher', 1), ('considers', 1), ('OK', 1), ('Guatemala', 1), ('Map', 1), ('Tufekci', 1), ('McWilliams', 1), ('one’s', 1), ('lawsuit', 1), ('Maxwell', 1), ('Reading', 1), ('growth', 1), ('Play', 1), ('Old', 1), ('Pistol', 1), ('prices', 1), ('together”', 1), ('Civil', 1), ('PilipeyEPA', 1), ('Barks', 1), ('Tiller', 1), ('Sea', 1), ('review', 1), ('Science', 1), ('Evergrande', 1), ('And', 1), ('Dead', 1), ('CC', 1), ('Broccoli', 1), ('hold', 1), ('Reportedly', 1), ('Michigan', 1), ('season', 1), ('Fruity', 1), ('FAA', 1), ('Nat', 1), ('Wirecutter’s', 1), ('Protests', 1), ('meals', 1), ('Murtaugh', 1), ('wordplay', 1), ('78', 1), ('→', 1), ('Industry', 1), ('Olive', 1), ('distance', 1), ('speeding', 1), ('NYC', 1), ('Defaults', 1), ('Vertex', 1), ('»', 1), ('Member', 1), ('I’ll', 1), ('Bryson', 1), ('testing', 1), ('Zandi', 1), ('Updates', 1), ('Mara', 1), ('Migrant', 1), ('evade', 1), ('leaders', 1), ('crowds', 1), ('Astronaut', 1), ('White', 1), ('recommended', 1), ('Paper', 1), ('Smollett', 1), ('dots', 1), ('parties', 1), ('‘Boring', 1), ('Menu', 1), ('🎉', 1), ('classconscious', 1), ('Guide', 1), ('Document', 1), ('putting', 1), ('national', 1), ('chairman', 1), ('Rests', 1), ('attic', 1), ('Considered', 1), ('Lerman', 1), ('investigation', 1), ('Contreras', 1), ('Hagen', 1), ('😳', 1), ('Today’s', 1), ('Returns', 1), ('‘Treeson’', 1), ('Primary', 1), ('Niko', 1), ('Game', 1), ('Original', 1), ('Chip', 1), ('Healthy', 1), ('Jeff', 1), ('Projectors', 1), ('deaths', 1), ('Allow', 1), ('Hold', 1), ('Award', 1), ('upside', 1), ('microwaved', 1), ('Year’', 1), ('evening', 1), ('License', 1), ('Brooklyn', 1), ('link', 1), ('linked', 1), ('Asserting', 1), ('GOP', 1), ('raised', 1), ('custom', 1), ('Boys', 1), ('‘And', 1), ('Hurley', 1), ('Regulators', 1), ('Tell', 1), ('pair', 1), ('hosting', 1), ('prison', 1), ('collars', 1), ('mandate', 1), ('FDIC’s', 1), ('kids', 1), ('KF94', 1), ('Teach', 1), ('reveal', 1), ('Republicans', 1), ('Perdue', 1), ('Real', 1), ('price', 1), ('National', 1), ('Break', 1), ('filed', 1), ('Trying', 1), ('usual', 1), ('isn’t', 1), ('38', 1), ('Now', 1), ('Anytime', 1), ('hidden', 1), ('visual', 1), ('Peng', 1), ('tennis', 1), ('Smoked', 1), ('fastest', 1), ('Need', 1), ('Paul', 1), ('Pekosz', 1), ('Arrived', 1), ('18', 1), ('Suspect’s', 1), ('vaccines', 1), ('sports', 1), ('evidence', 1), ('solicit', 1), ('Cathedral', 1), ('Mexico', 1), ('Jung', 1), ('thought', 1), ('Relax', 1), ('Jails', 1), ('that’s', 1), ('John', 1), ('Wirecutter', 1), ('Lifestyle', 1), ('Lying', 1), ('Yann', 1), ('collectors', 1), ('heated', 1), ('Living', 1), ('Press', 1), ('surgical', 1), ('Warner', 1), ('Sensational', 1), ('Letter', 1), ('Difficult', 1), ('BokatLindell', 1), ('Over', 1), ('Myers', 1), ('escapee', 1), ('Steel', 1), ('actor', 1), ('N95', 1), ('Williams', 1), ('Nick', 1), ('figure', 1), ('Deal', 1), ('SEARCH', 1), ('Accuser', 1), ('Ways', 1), ('Karen', 1), ('health', 1), ('Mandates', 1), ('Adam', 1), ('Die', 1), ('Lost', 1), ('Ron', 1), ('Happening', 1), ('Read', 1), ('Just', 1), ('Iconoclast', 1), ('angry', 1), ('Subdued', 1), ('reboot', 1), ('Down', 1), ('big', 1), ('Five', 1), ('中文', 1), ('judge', 1), ('120917', 1), ('Tips', 1), ('agenda', 1), ('Oyster', 1), ('trickier', 1), ('Turns', 1), ('hedge', 1), ('Ethan', 1), ('migrants', 1), ('owner', 1), ('GM’s', 1), ('Gathering', 1), ('Killing', 1), ('Sitemap', 1), ('‘Hell', 1), ('Hanna', 1), ('divorce', 1), ('Samantha', 1), ('Ultrarich', 1), ('Doing', 1), ('Sublime', 1), ('concerned', 1), ('GutierrezAssociated', 1), ('Sent', 1), ('Boxed', 1), ('Match', 1), ('Abortions', 1), ('Ask', 1), ('Still', 1), ('brighter', 1), ('BhaskarThe', 1), ('Prosecution', 1), ('plans', 1), ('evoked', 1), ('Murder', 1), ('Classes', 1), ('generations', 1), ('Between', 1), ('Son', 1), ('Roman', 1), ('Folk', 1), ('security', 1), ('Time', 1), ('Muscle', 1), ('Gods', 1), ('illustration', 1), ('detective', 1), ('elements', 1), ('searching', 1), ('Crash', 1), ('2022', 1), ('Potter', 1), ('Disrupting', 1), ('China’s', 1), ('Yechan', 1), ('changed', 1), ('Would', 1), ('Flatbreads', 1), ('Parents', 1), ('Were', 1), ('Oscar', 1), ('Accept', 1), ('projects', 1), ('McQuade', 1), ('Truck', 1), ('School', 1), ('Soon', 1), ('Shuai', 1), ('struggling', 1), ('commit', 1), ('Resilience', 1), ('Experts', 1), ('collect', 1), ('Subscribers', 1), ('Analysis', 1), ('receive', 1), ('Again', 1), ('Jan', 1), ('Scrivani', 1), ('Years', 1), ('Open', 1), ('Kelly', 1), ('sturdy', 1), ('Crossword', 1), ('Women', 1), ('Christina', 1), ('abortion', 1), ('Echoing', 1), ('2016', 1), ('wrong', 1), ('offers', 1), ('Money', 1), ('suggestion', 1), ('airplane', 1), ('agony', 1), ('reduced', 1), ('Tom', 1), ('gains', 1), ('chain', 1), ('projector', 1), ('Pans', 1), ('EpoxydudeGetty', 1), ('Sign', 1), ('hand', 1), ('Magic', 1), ('Avoid', 1), ('Sentenced', 1), ('pet', 1), ('CorumEPA', 1), ('dispute', 1), ('consumer', 1), ('weekend', 1), ('“What’s', 1), ('Hero', 1), ('At', 1), ('primary', 1), ('Week', 1), ('wind', 1), ('citizens', 1), ('🎁', 1), ('seasonal', 1), ('Include', 1), ('instinctual', 1), ('head', 1), ('Rikers', 1), ('To', 1), ('rulings', 1), ('tough', 1), ('Britain', 1), ('indoors', 1), ('psychotherapist', 1), ('Collide', 1), ('change', 1), ('flipped', 1), ('eager', 1), ('men', 1), ('Up', 1), ('Code', 1), ('Effect', 1), ('happily', 1), ('Nuts', 1), ('Presence', 1), ('bridge', 1), ('Glitz', 1), ('Examines', 1), ('player', 1), ('Gouda', 1), ('school', 1), ('Big', 1), ('Help', 1), ('McWhorter', 1), ('People', 1), ('Out', 1), ('Krugman', 1), ('4th', 1), ('Spencer', 1), ('vaccination', 1), ('acknowledged', 1), ('sitting', 1), ('Log', 1), ('Store', 1), ('handling', 1), ('medical', 1), ('PowerPoint', 1), ('Thompson', 1), ('Consult', 1), ('charge', 1), ('oven', 1), ('cleaned', 1), ('Contact', 1), ('City', 1), ('Nesmith', 1), ('Estate', 1), ('amp', 1), ('13', 1), ('Sale', 1), ('Murray', 1), ('‘Lived', 1), ('rose', 1), ('Proud', 1), ('inspired', 1), ('Won’t', 1), ('censor', 1), ('explicit', 1), ('Jamelle', 1), ('drafted', 1), ('touch', 1), ('energy', 1), ('Arkansas', 1), ('feels', 1), ('Isn’t', 1), ('Virus', 1), ('Upend', 1), ('Apple', 1), ('PostRoe', 1), ('Anna', 1), ('ritual', 1), ('Testifies', 1), ('cases', 1), ('Killer', 1), ('European', 1), ('masks', 1), ('Trial', 1), ('Transcripts', 1), ('Spelling', 1), ('rich', 1), ('Copy', 1), ('Well’s', 1), ('members', 1), ('trappings', 1), ('14day', 1), ('26', 1), ('presents', 1), ('federal', 1), ('Dole', 1), ('Little', 1), ('Shellfish', 1), ('struggled', 1), ('Jere', 1), ('Drive', 1), ('Bouie', 1), ('situations', 1), ('Ashley', 1), ('Doomsday', 1), ('Cultivate', 1), ('Dunn', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Default는 False로 True로 변경하여 내림차순 정렬\n",
    "print(w6.getWordsFrequency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9843b326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clued', 1), ('regulators', 1), ('Merto', 1), ('case', 1), ('sentence', 1), ('Gets', 1), ('Debt', 1), ('mandatory', 1), ('Rekindle', 1), ('criticized', 1), ('Holdover', 1), ('Continues', 1), ('Boom', 1), ('father', 1), ('Sufferer', 1), ('audience', 1), ('Before', 1), ('Cottom', 1), ('movie', 1), ('Electric', 1), ('worried', 1), ('Meadows’s', 1), ('unusual', 1), ('Prize', 1), ('written', 1), ('Vehicle', 1), ('Ingber', 1), ('Change', 1), ('Sections', 1), ('Going', 1), ('heater', 1), ('strong', 1), ('Armando', 1), ('rising', 1), ('Reserved', 1), ('protection', 1), ('tourists', 1), ('Alexander', 1), ('Liberties', 1), ('Apocalypse’', 1), ('Gift', 1), ('Redefine', 1), ('Putin’s', 1), ('trip', 1), ('SchreiberAgence', 1), ('Wyden', 1), ('Bezos', 1), ('Goes', 1), ('Americans', 1), ('London', 1), ('Elderly', 1), ('History', 1), ('trophy', 1), ('leggings', 1), ('Abortion', 1), ('ground', 1), ('Caron', 1), ('canvases', 1), ('soldiered', 1), ('Narrated', 1), ('ideas', 1), ('incarcerate', 1), ('economic', 1), ('Taxing', 1), ('Bob', 1), ('Has', 1), ('Use', 1), ('Prosecutor', 1), ('illustrates', 1), ('sanitizer', 1), ('Worst', 1), ('While', 1), ('expert', 1), ('Prison', 1), ('Slavery', 1), ('Anthony', 1), ('airport', 1), ('Nobel', 1), ('lines', 1), ('span', 1), ('succeed', 1), ('Félix', 1), ('Police', 1), ('faces', 1), ('night', 1), ('Ty', 1), ('‘Improvise', 1), ('Fresh', 1), ('Stainless', 1), ('Mortals', 1), ('board', 1), ('Violence', 1), ('Find', 1), ('Wired', 1), ('Gabriela', 1), ('BlankenhornHBO', 1), ('Bears', 1), ('City”', 1), ('King', 1), ('Books', 1), ('USbound', 1), ('Wrong', 1), ('Senate', 1), ('KN95', 1), ('Cooking', 1), ('Rip', 1), ('reactions', 1), ('Hester', 1), ('Rights', 1), ('Frijol', 1), ('tractortrailer', 1), ('America', 1), ('Jussie', 1), ('screening', 1), ('crammed', 1), ('Brain’', 1), ('‘Dr', 1), ('Death', 1), ('Bean', 1), ('releases', 1), ('Charged', 1), ('Gifts', 1), ('fleecelined', 1), ('Efforts', 1), ('reused', 1), ('rows', 1), ('great', 1), ('Will', 1), ('Despairing', 1), ('Salt', 1), ('we’d', 1), ('It’s', 1), ('Finish', 1), ('SomodevillaGetty', 1), ('ordered', 1), ('Gay', 1), ('Honor’', 1), ('claims', 1), ('Create', 1), ('boiled', 1), ('Briefing', 1), ('overwhelmed', 1), ('Clarkson', 1), ('gather', 1), ('sell', 1), ('hot', 1), ('Easy', 1), ('Bartlett', 1), ('Than', 1), ('Roving', 1), ('Kelso', 1), ('What’s', 1), ('ordinary', 1), ('NYTCo', 1), ('Cole', 1), ('Maria', 1), ('effects', 1), ('feel', 1), ('law', 1), ('meeting', 1), ('Me', 1), ('Lotus’', 1), ('industry', 1), ('Daily’', 1), ('Best', 1), ('Illustration', 1), ('Leaves', 1), ('Recommendations', 1), ('appears', 1), ('Man’', 1), ('Shooting', 1), ('NY', 1), ('Brooks', 1), ('McMillan', 1), ('Brenner', 1), ('My', 1), ('Different', 1), ('cut', 1), ('Mike', 1), ('Decombat', 1), ('Complacency', 1), ('gathering', 1), ('young', 1), ('Ukraine', 1), ('🎄', 1), ('Any', 1), ('Oil', 1), ('1308', 1), ('Allows', 1), ('Act', 1), ('Evening', 1), ('TaverniseNetflix', 1), ('“Sex', 1), ('lawyer', 1), ('Murillo', 1), ('Take', 1), ('Fish', 1), ('attractive', 1), ('Exercise', 1), ('Mr', 1), ('Oliver', 1), ('push', 1), ('Jancee', 1), ('Zeynep', 1), ('requirements', 1), ('Annies', 1), ('Oust', 1), ('Testa', 1), ('McDonald', 1), ('roll', 1), ('dishwasher', 1), ('His', 1), ('Blum', 1), ('✈️', 1), ('Brand', 1), ('So', 1), ('That’', 1), ('System', 1), ('Bank', 1), ('Another', 1), ('Bars', 1), ('Cadavers’', 1), ('Upgrade', 1), ('Wings', 1), ('Jelena', 1), ('Polls', 1), ('Corps', 1), ('Footage', 1), ('‘They', 1), ('Meadows', 1), ('Them', 1), ('lives', 1), ('Carnahan', 1), ('media', 1), ('Who', 1), ('frozen', 1), ('Service', 1), ('lastminute', 1), ('accessories', 1), ('Public', 1), ('spaces', 1), ('turn', 1), ('worn', 1), ('picking', 1), ('Tony', 1), ('disagree', 1), ('FrancePresse', 1), ('undercut', 1), ('Oaxacan', 1), ('Ressa', 1), ('Rift', 1), ('Starting', 1), ('continues', 1), ('‘Very', 1), ('Earbuds', 1), ('fundmanager', 1), ('Tiles', 1), ('festive', 1), ('“infiltration”', 1), ('Yoko', 1), ('declare', 1), ('dilemma', 1), ('slammed', 1), ('narrated', 1), ('suggestions', 1), ('Trust', 1), ('Having', 1), ('Gilbertson', 1), ('pace', 1), ('women', 1), ('SelfProclaimed', 1), ('Flawed', 1), ('pressure', 1), ('funeral', 1), ('paint', 1), ('Eulogizes', 1), ('response', 1), ('40', 1), ('Tougher', 1), ('comfortable', 1), ('events', 1), ('Pennsylvania', 1), ('Classics', 1), ('Dani', 1), ('grapple', 1), ('runner', 1), ('crisp', 1), ('chairwoman', 1), ('Dec', 1), ('Spectacle', 1), ('Vindman', 1), ('Awards', 1), ('Grant', 1), ('confronted', 1), ('safe', 1), ('Habit', 1), ('strikes', 1), ('Fierce', 1), ('days”', 1), ('“only', 1), ('Seeking', 1), ('Milder', 1), ('Meltaways', 1), ('Studio', 1), ('Finance', 1), ('Great', 1), ('Lemon', 1), ('B', 1), ('businesses', 1), ('Review', 1), ('list', 1), ('Subscriptions', 1), ('Then', 1), ('Try', 1), ('power', 1), ('Let', 1), ('Biden’s', 1), ('spots', 1), ('son', 1), ('Alex', 1), ('Revisit', 1), ('provide', 1), ('face', 1), ('patio', 1), ('🆘', 1), ('friend', 1), ('Cool', 1), ('tax', 1), ('walls', 1), ('1m', 1), ('Scam', 1), ('Talks', 1), ('doesn’t', 1), ('Rafael', 1), ('images', 1), ('suggests', 1), ('January', 1), ('80', 1), ('statute', 1), ('seemingly', 1), ('™', 1), ('Hidden', 1), ('star', 1), ('honor', 1), ('Tressie', 1), ('Navigation', 1), ('Shucks', 1), ('abortions', 1), ('Plan', 1), ('Stew', 1), ('Artist’s', 1), ('quality', 1), ('explain', 1), ('document', 1), ('‘Quiet', 1), ('Covid', 1), ('Johnathon', 1), ('that’”', 1), ('Don’t', 1), ('Newsletter', 1), ('pushback', 1), ('Connect', 1), ('kind', 1), ('Baleaf', 1), ('baseless', 1), ('‘O’', 1), ('perfect', 1), ('Ghislaine', 1), ('Law', 1), ('Went', 1), ('Senator', 1), ('Craig', 1), ('square', 1), ('cozy', 1), ('“We', 1), ('accomplish', 1), ('suicide', 1), ('Newsource', 1), ('Homes’', 1), ('Become', 1), ('Modern', 1), ('mother', 1), ('September', 1), ('Monkee’', 1), ('Albums', 1), ('I’ve', 1), ('Black', 1), ('surveys', 1), ('shielded', 1), ('cold', 1), ('tips', 1), ('picky', 1), ('delightful', 1), ('scientists', 1), ('Weigh', 1), ('Crumbley’s', 1), ('Samuel', 1), ('genres', 1), ('Address', 1), ('Bee', 1), ('chef', 1), ('Our', 1), ('Election', 1), ('cloth', 1), ('option', 1), ('Victories', 1), ('Sans', 1), ('Avg', 1), ('Prepare', 1), ('Ono', 1), ('bunch', 1), ('Say', 1), ('Statement', 1), ('Bigger', 1), ('participation', 1), ('refrigerated', 1), ('job', 1), ('highquality', 1), ('Friday', 1), ('Information', 1), ('emergency', 1), ('delivers', 1), ('double', 1), ('Debate', 1), ('nations', 1), ('He', 1), ('photograph', 1), ('painter', 1), ('puts', 1), ('Start', 1), ('drink', 1), ('silicone', 1), ('Item', 1), ('nonpartisan', 1), ('Offenses', 1), ('Stasher', 1), ('considers', 1), ('OK', 1), ('Guatemala', 1), ('Map', 1), ('Tufekci', 1), ('McWilliams', 1), ('one’s', 1), ('lawsuit', 1), ('Maxwell', 1), ('Reading', 1), ('growth', 1), ('Play', 1), ('Old', 1), ('Pistol', 1), ('prices', 1), ('together”', 1), ('Civil', 1), ('PilipeyEPA', 1), ('Barks', 1), ('Tiller', 1), ('Sea', 1), ('review', 1), ('Science', 1), ('Evergrande', 1), ('And', 1), ('Dead', 1), ('CC', 1), ('Broccoli', 1), ('hold', 1), ('Reportedly', 1), ('Michigan', 1), ('season', 1), ('Fruity', 1), ('FAA', 1), ('Nat', 1), ('Wirecutter’s', 1), ('Protests', 1), ('meals', 1), ('Murtaugh', 1), ('wordplay', 1), ('78', 1), ('→', 1), ('Industry', 1), ('Olive', 1), ('distance', 1), ('speeding', 1), ('NYC', 1), ('Defaults', 1), ('Vertex', 1), ('»', 1), ('Member', 1), ('I’ll', 1), ('Bryson', 1), ('testing', 1), ('Zandi', 1), ('Updates', 1), ('Mara', 1), ('Migrant', 1), ('evade', 1), ('leaders', 1), ('crowds', 1), ('Astronaut', 1), ('White', 1), ('recommended', 1), ('Paper', 1), ('Smollett', 1), ('dots', 1), ('parties', 1), ('‘Boring', 1), ('Menu', 1), ('🎉', 1), ('classconscious', 1), ('Guide', 1), ('Document', 1), ('putting', 1), ('national', 1), ('chairman', 1), ('Rests', 1), ('attic', 1), ('Considered', 1), ('Lerman', 1), ('investigation', 1), ('Contreras', 1), ('Hagen', 1), ('😳', 1), ('Today’s', 1), ('Returns', 1), ('‘Treeson’', 1), ('Primary', 1), ('Niko', 1), ('Game', 1), ('Original', 1), ('Chip', 1), ('Healthy', 1), ('Jeff', 1), ('Projectors', 1), ('deaths', 1), ('Allow', 1), ('Hold', 1), ('Award', 1), ('upside', 1), ('microwaved', 1), ('Year’', 1), ('evening', 1), ('License', 1), ('Brooklyn', 1), ('link', 1), ('linked', 1), ('Asserting', 1), ('GOP', 1), ('raised', 1), ('custom', 1), ('Boys', 1), ('‘And', 1), ('Hurley', 1), ('Regulators', 1), ('Tell', 1), ('pair', 1), ('hosting', 1), ('collars', 1), ('mandate', 1), ('FDIC’s', 1), ('kids', 1), ('KF94', 1), ('Teach', 1), ('reveal', 1), ('Republicans', 1), ('Perdue', 1), ('Real', 1), ('price', 1), ('National', 1), ('Break', 1), ('filed', 1), ('Trying', 1), ('usual', 1), ('isn’t', 1), ('38', 1), ('Now', 1), ('Anytime', 1), ('hidden', 1), ('visual', 1), ('Peng', 1), ('tennis', 1), ('Smoked', 1), ('fastest', 1), ('Need', 1), ('Paul', 1), ('Pekosz', 1), ('Arrived', 1), ('18', 1), ('Suspect’s', 1), ('vaccines', 1), ('sports', 1), ('evidence', 1), ('solicit', 1), ('Cathedral', 1), ('Mexico', 1), ('Jung', 1), ('thought', 1), ('Relax', 1), ('Jails', 1), ('One', 1), ('that’s', 1), ('John', 1), ('Wirecutter', 1), ('Lifestyle', 1), ('Lying', 1), ('Yann', 1), ('Several', 1), ('collectors', 1), ('heated', 1), ('Living', 1), ('Press', 1), ('surgical', 1), ('Warner', 1), ('Sensational', 1), ('Letter', 1), ('Difficult', 1), ('BokatLindell', 1), ('Over', 1), ('Myers', 1), ('Steel', 1), ('actor', 1), ('N95', 1), ('Williams', 1), ('Nick', 1), ('figure', 1), ('Deal', 1), ('SEARCH', 1), ('Accuser', 1), ('Ways', 1), ('Karen', 1), ('health', 1), ('Mandates', 1), ('Adam', 1), ('Die', 1), ('Lost', 1), ('Ron', 1), ('Happening', 1), ('Just', 1), ('Iconoclast', 1), ('angry', 1), ('Subdued', 1), ('reboot', 1), ('Down', 1), ('big', 1), ('Five', 1), ('中文', 1), ('judge', 1), ('120917', 1), ('Tips', 1), ('agenda', 1), ('Oyster', 1), ('trickier', 1), ('Turns', 1), ('hedge', 1), ('Ethan', 1), ('migrants', 1), ('owner', 1), ('GM’s', 1), ('Gathering', 1), ('Sitemap', 1), ('‘Hell', 1), ('Hanna', 1), ('divorce', 1), ('Samantha', 1), ('Ultrarich', 1), ('Doing', 1), ('Sublime', 1), ('concerned', 1), ('GutierrezAssociated', 1), ('Sent', 1), ('Boxed', 1), ('Match', 1), ('Abortions', 1), ('Ask', 1), ('Still', 1), ('brighter', 1), ('BhaskarThe', 1), ('Prosecution', 1), ('plans', 1), ('evoked', 1), ('Classes', 1), ('generations', 1), ('Between', 1), ('Son', 1), ('Roman', 1), ('Folk', 1), ('security', 1), ('Time', 1), ('Muscle', 1), ('Gods', 1), ('illustration', 1), ('elements', 1), ('searching', 1), ('Crash', 1), ('2022', 1), ('Potter', 1), ('Disrupting', 1), ('China’s', 1), ('Yechan', 1), ('changed', 1), ('Would', 1), ('Flatbreads', 1), ('Parents', 1), ('Were', 1), ('Oscar', 1), ('Accept', 1), ('projects', 1), ('McQuade', 1), ('Truck', 1), ('School', 1), ('Soon', 1), ('Shuai', 1), ('struggling', 1), ('commit', 1), ('Resilience', 1), ('Experts', 1), ('collect', 1), ('Subscribers', 1), ('Analysis', 1), ('receive', 1), ('Again', 1), ('Jan', 1), ('Scrivani', 1), ('Years', 1), ('Open', 1), ('Kelly', 1), ('sturdy', 1), ('Crossword', 1), ('Women', 1), ('Christina', 1), ('abortion', 1), ('Echoing', 1), ('2016', 1), ('wrong', 1), ('offers', 1), ('Money', 1), ('suggestion', 1), ('airplane', 1), ('agony', 1), ('reduced', 1), ('Tom', 1), ('gains', 1), ('chain', 1), ('projector', 1), ('Pans', 1), ('EpoxydudeGetty', 1), ('Sign', 1), ('hand', 1), ('Magic', 1), ('Avoid', 1), ('Sentenced', 1), ('pet', 1), ('CorumEPA', 1), ('dispute', 1), ('consumer', 1), ('weekend', 1), ('“What’s', 1), ('Hero', 1), ('At', 1), ('primary', 1), ('Week', 1), ('wind', 1), ('citizens', 1), ('🎁', 1), ('seasonal', 1), ('Include', 1), ('instinctual', 1), ('head', 1), ('Rikers', 1), ('To', 1), ('rulings', 1), ('tough', 1), ('Britain', 1), ('indoors', 1), ('psychotherapist', 1), ('Collide', 1), ('change', 1), ('flipped', 1), ('Killed', 1), ('eager', 1), ('men', 1), ('Up', 1), ('Code', 1), ('Effect', 1), ('happily', 1), ('Nuts', 1), ('Presence', 1), ('bridge', 1), ('Glitz', 1), ('Examines', 1), ('player', 1), ('Gouda', 1), ('school', 1), ('Big', 1), ('Help', 1), ('McWhorter', 1), ('Out', 1), ('Krugman', 1), ('4th', 1), ('Spencer', 1), ('vaccination', 1), ('acknowledged', 1), ('sitting', 1), ('Log', 1), ('Store', 1), ('handling', 1), ('medical', 1), ('Tornadoes', 1), ('PowerPoint', 1), ('Thompson', 1), ('Consult', 1), ('charge', 1), ('oven', 1), ('cleaned', 1), ('Contact', 1), ('City', 1), ('Nesmith', 1), ('Estate', 1), ('amp', 1), ('13', 1), ('Sale', 1), ('Murray', 1), ('‘Lived', 1), ('rose', 1), ('Proud', 1), ('inspired', 1), ('Won’t', 1), ('censor', 1), ('explicit', 1), ('Jamelle', 1), ('drafted', 1), ('touch', 1), ('energy', 1), ('feels', 1), ('Isn’t', 1), ('Virus', 1), ('Upend', 1), ('Apple', 1), ('PostRoe', 1), ('Anna', 1), ('ritual', 1), ('Testifies', 1), ('cases', 1), ('Killer', 1), ('European', 1), ('masks', 1), ('Trial', 1), ('Transcripts', 1), ('Spelling', 1), ('rich', 1), ('Copy', 1), ('Well’s', 1), ('members', 1), ('trappings', 1), ('14day', 1), ('26', 1), ('presents', 1), ('federal', 1), ('Dole', 1), ('Little', 1), ('Shellfish', 1), ('struggled', 1), ('Jere', 1), ('Drive', 1), ('Bouie', 1), ('situations', 1), ('Ashley', 1), ('Doomsday', 1), ('Cultivate', 1), ('Dunn', 1), ('Arabic', 2), ('break', 2), ('Economy', 2), ('Facts', 2), ('Schedule', 2), ('Mich', 2), ('Malosh', 2), ('Freedom', 2), ('Investigations', 2), ('years', 2), ('Mission', 2), ('Stay', 2), ('Binge', 2), ('Inside', 2), ('bags', 2), ('increases', 2), ('Coy', 2), ('Relationships', 2), ('Privacy', 2), ('T', 2), ('flying', 2), ('Presidency', 2), ('site', 2), ('Could', 2), ('Golf', 2), ('Football', 2), ('Supreme', 2), ('friends', 2), ('Architecture', 2), ('HLN', 2), ('experts', 2), ('Impact', 2), ('Opinion', 2), ('AZ', 2), ('Peter', 2), ('Vaccine', 2), ('First', 2), ('planning', 2), ('CNNVR', 2), ('Luxury', 2), ('Innovate', 2), ('Middle', 2), ('Mindfulness', 2), ('Heroes', 2), ('Profiles', 2), ('Ad', 2), ('don’t', 2), ('Ahead', 2), ('Edition', 2), ('Europe', 2), ('Equals', 2), ('Asia', 2), ('Coronavirus', 2), ('Well', 2), ('space', 2), ('Elections', 2), ('Digital', 2), ('election', 2), ('court', 2), ('gift', 2), ('Tennis', 2), ('reality', 2), ('Minn', 2), ('‘The', 2), ('Photos', 2), ('Design', 2), ('Global', 2), ('County', 2), ('require', 2), ('Canada', 2), ('Screen', 2), ('gatherings', 2), ('Longform', 2), ('letters', 2), ('detected', 2), ('Success', 2), ('Wildfire', 2), ('Nothing', 2), ('bans', 2), ('trackers', 2), ('Esports', 2), ('Fitness', 2), ('ParkerPope', 2), ('Tamales', 2), ('Follow', 2), ('Stars', 2), ('Tokyo', 2), ('Its', 2), ('Beatles', 2), ('Markets', 2), ('unvaccinated', 2), ('Leadership', 2), ('Be', 2), ('Inflation', 2), ('weeks', 2), ('Articles', 2), ('I’m', 2), ('Cable', 2), ('pregnancy', 2), ('Accessibility', 2), ('Gadget', 2), ('Sarahbeth', 2), ('Shutterstock', 2), ('Studios', 2), ('Cities', 2), ('From', 2), ('Choices', 2), ('Had', 2), ('After', 2), ('Foreseeable', 2), ('content', 2), ('winter', 2), ('On', 2), ('Live', 2), ('Jersey', 2), ('E', 2), ('safely', 2), ('Weather', 2), ('Destinations', 2), ('10', 2), ('picture', 2), ('Films', 2), ('Transformed', 2), ('Upstarts', 2), ('Project', 2), ('county', 2), ('Kingdom', 2), ('Magazine', 2), ('Nursing', 2), ('Climbing', 2), ('Degrees', 2), ('France', 2), ('Fashion', 2), ('day', 2), ('Getting', 2), ('Tara', 2), ('ManeyThe', 2), ('Breaking', 2), ('NH', 2), ('Site', 2), ('Motorsport', 2), ('Policy', 2), ('India', 2), ('This', 2), ('it’s', 2), ('Network', 2), ('In', 2), ('Australia', 2), ('Americas', 2), ('Perspectives', 2), ('Challenge', 2), ('Climate', 2), ('Innovative', 2), ('Future', 2), ('eat', 2), ('Give', 2), ('long', 2), ('Company', 2), ('decision', 2), ('Earth', 2), ('holiday', 2), ('Clean', 2), ('Listen', 2), ('Call', 2), ('Committee', 2), ('Sleep', 2), ('Advertise', 2), ('Storm', 2), ('pandemic', 2), ('Formula', 2), ('Photo', 2), ('Beauty', 2), ('Drink', 2), ('East', 2), ('We’re', 3), ('Español', 3), ('©', 3), ('Mark', 3), ('Search', 3), ('Terms', 3), ('public', 3), ('Learn', 3), ('Us', 3), ('guide', 3), ('2020', 3), ('Newsletters', 3), ('Washington', 3), ('Better', 3), ('Small', 3), ('Michael', 3), ('advice', 3), ('Trump', 3), ('holidays', 3), ('Entertainment', 3), ('time', 3), ('China', 3), ('Like', 3), ('you’re', 3), ('short', 3), ('With', 3), ('Arts', 3), ('Look', 3), ('Skip', 3), ('That', 3), ('Other', 3), ('Home', 3), ('About', 3), ('Tracking', 3), ('Do', 3), ('UK', 3), ('social', 3), ('Habits', 3), ('Holiday', 3), ('Shows', 3), ('Where', 3), ('Texas', 3), ('Make', 3), ('Features', 4), ('Style', 4), ('But', 4), ('Travel', 4), ('Business', 4), ('2021', 4), ('family', 4), ('Getty', 4), ('vaccinations', 4), ('Life', 4), ('Your', 4), ('Why', 4), ('Politics', 4), ('As', 4), ('Here’s', 4), ('Health', 4), ('Andrew', 4), ('Culture', 4), ('Court', 4), ('More', 4), ('Is', 4), ('Africa', 4), ('Tracker', 4), ('Food', 5), ('What', 5), ('reading', 5), ('You', 5), ('David', 5), ('International', 5), ('Media', 5), ('main', 5), ('Continue', 5), ('All', 5), ('Tech', 5), ('President', 5), ('Advertisement', 5), ('Can', 5), ('States', 5), ('Celebrating', 6), ('Are', 6), ('United', 6), ('We', 6), ('Sports', 6), ('It', 6), ('Work', 6), ('TV', 6), ('story', 6), ('Biden', 6), ('For', 6), ('Images', 6), ('Video', 6), ('If', 7), ('A', 7), ('Omicron', 7), ('mask', 8), ('Holidays', 8), ('Videos', 8), ('›', 8), ('World', 9), ('Through', 10), ('Get', 11), ('News', 11), ('How', 16), ('US', 17), ('CNN', 19), ('Times', 20), ('York', 23), ('New', 28), ('The', 30)]\n"
     ]
    }
   ],
   "source": [
    "# 2.2 reverse = True 입력시 True를 False로 변경하여 오름차순 정렬\n",
    "print(w6.getWordsFrequency(reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c27257cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clued', 1)\n",
      "('regulators', 1)\n",
      "('Merto', 1)\n",
      "('case', 1)\n",
      "('sentence', 1)\n",
      "('Gets', 1)\n",
      "('Debt', 1)\n",
      "('mandatory', 1)\n",
      "('Rekindle', 1)\n",
      "('criticized', 1)\n",
      "('Holdover', 1)\n",
      "('Continues', 1)\n",
      "('Boom', 1)\n",
      "('father', 1)\n",
      "('Sufferer', 1)\n",
      "('audience', 1)\n",
      "('Before', 1)\n",
      "('Cottom', 1)\n",
      "('movie', 1)\n",
      "('Electric', 1)\n",
      "('worried', 1)\n",
      "('Meadows’s', 1)\n",
      "('unusual', 1)\n",
      "('Prize', 1)\n",
      "('written', 1)\n",
      "('Vehicle', 1)\n",
      "('Ingber', 1)\n",
      "('Change', 1)\n",
      "('Sections', 1)\n",
      "('Going', 1)\n",
      "('heater', 1)\n",
      "('strong', 1)\n",
      "('Armando', 1)\n",
      "('rising', 1)\n",
      "('Reserved', 1)\n",
      "('protection', 1)\n",
      "('tourists', 1)\n",
      "('Alexander', 1)\n",
      "('Liberties', 1)\n",
      "('Apocalypse’', 1)\n",
      "('Gift', 1)\n",
      "('Redefine', 1)\n",
      "('Putin’s', 1)\n",
      "('trip', 1)\n",
      "('SchreiberAgence', 1)\n",
      "('Wyden', 1)\n",
      "('Bezos', 1)\n",
      "('Goes', 1)\n",
      "('Americans', 1)\n",
      "('London', 1)\n",
      "('Elderly', 1)\n",
      "('History', 1)\n",
      "('trophy', 1)\n",
      "('leggings', 1)\n",
      "('Abortion', 1)\n",
      "('ground', 1)\n",
      "('Caron', 1)\n",
      "('canvases', 1)\n",
      "('soldiered', 1)\n",
      "('Narrated', 1)\n",
      "('ideas', 1)\n",
      "('incarcerate', 1)\n",
      "('economic', 1)\n",
      "('Taxing', 1)\n",
      "('Bob', 1)\n",
      "('Has', 1)\n",
      "('Use', 1)\n",
      "('Prosecutor', 1)\n",
      "('illustrates', 1)\n",
      "('sanitizer', 1)\n",
      "('Worst', 1)\n",
      "('While', 1)\n",
      "('expert', 1)\n",
      "('Prison', 1)\n",
      "('Slavery', 1)\n",
      "('Anthony', 1)\n",
      "('airport', 1)\n",
      "('Nobel', 1)\n",
      "('lines', 1)\n",
      "('span', 1)\n",
      "('succeed', 1)\n",
      "('Félix', 1)\n",
      "('Police', 1)\n",
      "('faces', 1)\n",
      "('night', 1)\n",
      "('Ty', 1)\n",
      "('‘Improvise', 1)\n",
      "('Fresh', 1)\n",
      "('Stainless', 1)\n",
      "('Mortals', 1)\n",
      "('board', 1)\n",
      "('Violence', 1)\n",
      "('Find', 1)\n",
      "('Wired', 1)\n",
      "('Gabriela', 1)\n",
      "('BlankenhornHBO', 1)\n",
      "('Bears', 1)\n",
      "('City”', 1)\n",
      "('King', 1)\n",
      "('Books', 1)\n",
      "('USbound', 1)\n",
      "('Wrong', 1)\n",
      "('Senate', 1)\n",
      "('KN95', 1)\n",
      "('Cooking', 1)\n",
      "('Rip', 1)\n",
      "('reactions', 1)\n",
      "('Hester', 1)\n",
      "('Rights', 1)\n",
      "('Frijol', 1)\n",
      "('tractortrailer', 1)\n",
      "('America', 1)\n",
      "('Jussie', 1)\n",
      "('screening', 1)\n",
      "('crammed', 1)\n",
      "('Brain’', 1)\n",
      "('‘Dr', 1)\n",
      "('Death', 1)\n",
      "('Bean', 1)\n",
      "('releases', 1)\n",
      "('Charged', 1)\n",
      "('Gifts', 1)\n",
      "('fleecelined', 1)\n",
      "('Efforts', 1)\n",
      "('reused', 1)\n",
      "('rows', 1)\n",
      "('great', 1)\n",
      "('Will', 1)\n",
      "('Despairing', 1)\n",
      "('Salt', 1)\n",
      "('we’d', 1)\n",
      "('It’s', 1)\n",
      "('Finish', 1)\n",
      "('SomodevillaGetty', 1)\n",
      "('ordered', 1)\n",
      "('Gay', 1)\n",
      "('Honor’', 1)\n",
      "('claims', 1)\n",
      "('Create', 1)\n",
      "('boiled', 1)\n",
      "('Briefing', 1)\n",
      "('overwhelmed', 1)\n",
      "('Clarkson', 1)\n",
      "('gather', 1)\n",
      "('sell', 1)\n",
      "('hot', 1)\n",
      "('Easy', 1)\n",
      "('Bartlett', 1)\n",
      "('Than', 1)\n",
      "('Roving', 1)\n",
      "('Kelso', 1)\n",
      "('What’s', 1)\n",
      "('ordinary', 1)\n",
      "('NYTCo', 1)\n",
      "('Cole', 1)\n",
      "('Maria', 1)\n",
      "('effects', 1)\n",
      "('feel', 1)\n",
      "('law', 1)\n",
      "('meeting', 1)\n",
      "('Me', 1)\n",
      "('Lotus’', 1)\n",
      "('industry', 1)\n",
      "('Daily’', 1)\n",
      "('Best', 1)\n",
      "('Illustration', 1)\n",
      "('Leaves', 1)\n",
      "('Recommendations', 1)\n",
      "('appears', 1)\n",
      "('Man’', 1)\n",
      "('Shooting', 1)\n",
      "('NY', 1)\n",
      "('Brooks', 1)\n",
      "('McMillan', 1)\n",
      "('Brenner', 1)\n",
      "('My', 1)\n",
      "('Different', 1)\n",
      "('cut', 1)\n",
      "('Mike', 1)\n",
      "('Decombat', 1)\n",
      "('Complacency', 1)\n",
      "('gathering', 1)\n",
      "('young', 1)\n",
      "('Ukraine', 1)\n",
      "('🎄', 1)\n",
      "('Any', 1)\n",
      "('Oil', 1)\n",
      "('1308', 1)\n",
      "('Allows', 1)\n",
      "('Act', 1)\n",
      "('Evening', 1)\n",
      "('TaverniseNetflix', 1)\n",
      "('“Sex', 1)\n",
      "('lawyer', 1)\n",
      "('Murillo', 1)\n",
      "('Take', 1)\n",
      "('Fish', 1)\n",
      "('attractive', 1)\n",
      "('Exercise', 1)\n",
      "('Mr', 1)\n",
      "('Oliver', 1)\n",
      "('push', 1)\n",
      "('Jancee', 1)\n",
      "('Zeynep', 1)\n",
      "('requirements', 1)\n",
      "('Annies', 1)\n",
      "('Oust', 1)\n",
      "('Testa', 1)\n",
      "('McDonald', 1)\n",
      "('roll', 1)\n",
      "('dishwasher', 1)\n",
      "('His', 1)\n",
      "('Blum', 1)\n",
      "('✈️', 1)\n",
      "('Brand', 1)\n",
      "('So', 1)\n",
      "('That’', 1)\n",
      "('System', 1)\n",
      "('Bank', 1)\n",
      "('Another', 1)\n",
      "('Bars', 1)\n",
      "('Cadavers’', 1)\n",
      "('Upgrade', 1)\n",
      "('Wings', 1)\n",
      "('Jelena', 1)\n",
      "('Polls', 1)\n",
      "('Corps', 1)\n",
      "('Footage', 1)\n",
      "('‘They', 1)\n",
      "('Meadows', 1)\n",
      "('Them', 1)\n",
      "('lives', 1)\n",
      "('Carnahan', 1)\n",
      "('media', 1)\n",
      "('Who', 1)\n",
      "('frozen', 1)\n",
      "('Service', 1)\n",
      "('lastminute', 1)\n",
      "('accessories', 1)\n",
      "('Public', 1)\n",
      "('spaces', 1)\n",
      "('turn', 1)\n",
      "('worn', 1)\n",
      "('picking', 1)\n",
      "('Tony', 1)\n",
      "('disagree', 1)\n",
      "('FrancePresse', 1)\n",
      "('undercut', 1)\n",
      "('Oaxacan', 1)\n",
      "('Ressa', 1)\n",
      "('Rift', 1)\n",
      "('Starting', 1)\n",
      "('continues', 1)\n",
      "('‘Very', 1)\n",
      "('Earbuds', 1)\n",
      "('fundmanager', 1)\n",
      "('Tiles', 1)\n",
      "('festive', 1)\n",
      "('“infiltration”', 1)\n",
      "('Yoko', 1)\n",
      "('declare', 1)\n",
      "('dilemma', 1)\n",
      "('slammed', 1)\n",
      "('narrated', 1)\n",
      "('suggestions', 1)\n",
      "('Trust', 1)\n",
      "('Having', 1)\n",
      "('Gilbertson', 1)\n",
      "('pace', 1)\n",
      "('women', 1)\n",
      "('SelfProclaimed', 1)\n",
      "('Flawed', 1)\n",
      "('pressure', 1)\n",
      "('funeral', 1)\n",
      "('paint', 1)\n",
      "('Eulogizes', 1)\n",
      "('response', 1)\n",
      "('40', 1)\n",
      "('Tougher', 1)\n",
      "('comfortable', 1)\n",
      "('events', 1)\n",
      "('Pennsylvania', 1)\n",
      "('Classics', 1)\n",
      "('Dani', 1)\n",
      "('grapple', 1)\n",
      "('runner', 1)\n",
      "('crisp', 1)\n",
      "('chairwoman', 1)\n",
      "('Dec', 1)\n",
      "('Spectacle', 1)\n",
      "('Vindman', 1)\n",
      "('Awards', 1)\n",
      "('Grant', 1)\n",
      "('confronted', 1)\n",
      "('safe', 1)\n",
      "('Habit', 1)\n",
      "('strikes', 1)\n",
      "('Fierce', 1)\n",
      "('days”', 1)\n",
      "('“only', 1)\n",
      "('Seeking', 1)\n",
      "('Milder', 1)\n",
      "('Meltaways', 1)\n",
      "('Studio', 1)\n",
      "('Finance', 1)\n",
      "('Great', 1)\n",
      "('Lemon', 1)\n",
      "('B', 1)\n",
      "('businesses', 1)\n",
      "('Review', 1)\n",
      "('list', 1)\n",
      "('Subscriptions', 1)\n",
      "('Then', 1)\n",
      "('Try', 1)\n",
      "('power', 1)\n",
      "('Let', 1)\n",
      "('Biden’s', 1)\n",
      "('spots', 1)\n",
      "('son', 1)\n",
      "('Alex', 1)\n",
      "('Revisit', 1)\n",
      "('provide', 1)\n",
      "('face', 1)\n",
      "('patio', 1)\n",
      "('🆘', 1)\n",
      "('friend', 1)\n",
      "('Cool', 1)\n",
      "('tax', 1)\n",
      "('walls', 1)\n",
      "('1m', 1)\n",
      "('Scam', 1)\n",
      "('Talks', 1)\n",
      "('doesn’t', 1)\n",
      "('Rafael', 1)\n",
      "('images', 1)\n",
      "('suggests', 1)\n",
      "('January', 1)\n",
      "('80', 1)\n",
      "('statute', 1)\n",
      "('seemingly', 1)\n",
      "('™', 1)\n",
      "('Hidden', 1)\n",
      "('star', 1)\n",
      "('honor', 1)\n",
      "('Tressie', 1)\n",
      "('Navigation', 1)\n",
      "('Shucks', 1)\n",
      "('abortions', 1)\n",
      "('Plan', 1)\n",
      "('Stew', 1)\n",
      "('Artist’s', 1)\n",
      "('quality', 1)\n",
      "('explain', 1)\n",
      "('document', 1)\n",
      "('‘Quiet', 1)\n",
      "('Covid', 1)\n",
      "('Johnathon', 1)\n",
      "('that’”', 1)\n",
      "('Don’t', 1)\n",
      "('Newsletter', 1)\n",
      "('pushback', 1)\n",
      "('Connect', 1)\n",
      "('kind', 1)\n",
      "('Baleaf', 1)\n",
      "('baseless', 1)\n",
      "('‘O’', 1)\n",
      "('perfect', 1)\n",
      "('Ghislaine', 1)\n",
      "('Law', 1)\n",
      "('Went', 1)\n",
      "('Senator', 1)\n",
      "('Craig', 1)\n",
      "('square', 1)\n",
      "('cozy', 1)\n",
      "('“We', 1)\n",
      "('accomplish', 1)\n",
      "('suicide', 1)\n",
      "('Newsource', 1)\n",
      "('Homes’', 1)\n",
      "('Become', 1)\n",
      "('Modern', 1)\n",
      "('mother', 1)\n",
      "('September', 1)\n",
      "('Monkee’', 1)\n",
      "('Albums', 1)\n",
      "('I’ve', 1)\n",
      "('Black', 1)\n",
      "('surveys', 1)\n",
      "('shielded', 1)\n",
      "('cold', 1)\n",
      "('tips', 1)\n",
      "('picky', 1)\n",
      "('delightful', 1)\n",
      "('scientists', 1)\n",
      "('Weigh', 1)\n",
      "('Crumbley’s', 1)\n",
      "('Samuel', 1)\n",
      "('genres', 1)\n",
      "('Address', 1)\n",
      "('Bee', 1)\n",
      "('chef', 1)\n",
      "('Our', 1)\n",
      "('Election', 1)\n",
      "('cloth', 1)\n",
      "('option', 1)\n",
      "('Victories', 1)\n",
      "('Sans', 1)\n",
      "('Avg', 1)\n",
      "('Prepare', 1)\n",
      "('Ono', 1)\n",
      "('bunch', 1)\n",
      "('Say', 1)\n",
      "('Statement', 1)\n",
      "('Bigger', 1)\n",
      "('participation', 1)\n",
      "('refrigerated', 1)\n",
      "('job', 1)\n",
      "('highquality', 1)\n",
      "('Friday', 1)\n",
      "('Information', 1)\n",
      "('emergency', 1)\n",
      "('delivers', 1)\n",
      "('double', 1)\n",
      "('Debate', 1)\n",
      "('nations', 1)\n",
      "('He', 1)\n",
      "('photograph', 1)\n",
      "('painter', 1)\n",
      "('puts', 1)\n",
      "('Start', 1)\n",
      "('drink', 1)\n",
      "('silicone', 1)\n",
      "('Item', 1)\n",
      "('nonpartisan', 1)\n",
      "('Offenses', 1)\n",
      "('Stasher', 1)\n",
      "('considers', 1)\n",
      "('OK', 1)\n",
      "('Guatemala', 1)\n",
      "('Map', 1)\n",
      "('Tufekci', 1)\n",
      "('McWilliams', 1)\n",
      "('one’s', 1)\n",
      "('lawsuit', 1)\n",
      "('Maxwell', 1)\n",
      "('Reading', 1)\n",
      "('growth', 1)\n",
      "('Play', 1)\n",
      "('Old', 1)\n",
      "('Pistol', 1)\n",
      "('prices', 1)\n",
      "('together”', 1)\n",
      "('Civil', 1)\n",
      "('PilipeyEPA', 1)\n",
      "('Barks', 1)\n",
      "('Tiller', 1)\n",
      "('Sea', 1)\n",
      "('review', 1)\n",
      "('Science', 1)\n",
      "('Evergrande', 1)\n",
      "('And', 1)\n",
      "('Dead', 1)\n",
      "('CC', 1)\n",
      "('Broccoli', 1)\n",
      "('hold', 1)\n",
      "('Reportedly', 1)\n",
      "('Michigan', 1)\n",
      "('season', 1)\n",
      "('Fruity', 1)\n",
      "('FAA', 1)\n",
      "('Nat', 1)\n",
      "('Wirecutter’s', 1)\n",
      "('Protests', 1)\n",
      "('meals', 1)\n",
      "('Murtaugh', 1)\n",
      "('wordplay', 1)\n",
      "('78', 1)\n",
      "('→', 1)\n",
      "('Industry', 1)\n",
      "('Olive', 1)\n",
      "('distance', 1)\n",
      "('speeding', 1)\n",
      "('NYC', 1)\n",
      "('Defaults', 1)\n",
      "('Vertex', 1)\n",
      "('»', 1)\n",
      "('Member', 1)\n",
      "('I’ll', 1)\n",
      "('Bryson', 1)\n",
      "('testing', 1)\n",
      "('Zandi', 1)\n",
      "('Updates', 1)\n",
      "('Mara', 1)\n",
      "('Migrant', 1)\n",
      "('evade', 1)\n",
      "('leaders', 1)\n",
      "('crowds', 1)\n",
      "('Astronaut', 1)\n",
      "('White', 1)\n",
      "('recommended', 1)\n",
      "('Paper', 1)\n",
      "('Smollett', 1)\n",
      "('dots', 1)\n",
      "('parties', 1)\n",
      "('‘Boring', 1)\n",
      "('Menu', 1)\n",
      "('🎉', 1)\n",
      "('classconscious', 1)\n",
      "('Guide', 1)\n",
      "('Document', 1)\n",
      "('putting', 1)\n",
      "('national', 1)\n",
      "('chairman', 1)\n",
      "('Rests', 1)\n",
      "('attic', 1)\n",
      "('Considered', 1)\n",
      "('Lerman', 1)\n",
      "('investigation', 1)\n",
      "('Contreras', 1)\n",
      "('Hagen', 1)\n",
      "('😳', 1)\n",
      "('Today’s', 1)\n",
      "('Returns', 1)\n",
      "('‘Treeson’', 1)\n",
      "('Primary', 1)\n",
      "('Niko', 1)\n",
      "('Game', 1)\n",
      "('Original', 1)\n",
      "('Chip', 1)\n",
      "('Healthy', 1)\n",
      "('Jeff', 1)\n",
      "('Projectors', 1)\n",
      "('deaths', 1)\n",
      "('Allow', 1)\n",
      "('Hold', 1)\n",
      "('Award', 1)\n",
      "('upside', 1)\n",
      "('microwaved', 1)\n",
      "('Year’', 1)\n",
      "('evening', 1)\n",
      "('License', 1)\n",
      "('Brooklyn', 1)\n",
      "('link', 1)\n",
      "('linked', 1)\n",
      "('Asserting', 1)\n",
      "('GOP', 1)\n",
      "('raised', 1)\n",
      "('custom', 1)\n",
      "('Boys', 1)\n",
      "('‘And', 1)\n",
      "('Hurley', 1)\n",
      "('Regulators', 1)\n",
      "('Tell', 1)\n",
      "('pair', 1)\n",
      "('hosting', 1)\n",
      "('collars', 1)\n",
      "('mandate', 1)\n",
      "('FDIC’s', 1)\n",
      "('kids', 1)\n",
      "('KF94', 1)\n",
      "('Teach', 1)\n",
      "('reveal', 1)\n",
      "('Republicans', 1)\n",
      "('Perdue', 1)\n",
      "('Real', 1)\n",
      "('price', 1)\n",
      "('National', 1)\n",
      "('Break', 1)\n",
      "('filed', 1)\n",
      "('Trying', 1)\n",
      "('usual', 1)\n",
      "('isn’t', 1)\n",
      "('38', 1)\n",
      "('Now', 1)\n",
      "('Anytime', 1)\n",
      "('hidden', 1)\n",
      "('visual', 1)\n",
      "('Peng', 1)\n",
      "('tennis', 1)\n",
      "('Smoked', 1)\n",
      "('fastest', 1)\n",
      "('Need', 1)\n",
      "('Paul', 1)\n",
      "('Pekosz', 1)\n",
      "('Arrived', 1)\n",
      "('18', 1)\n",
      "('Suspect’s', 1)\n",
      "('vaccines', 1)\n",
      "('sports', 1)\n",
      "('evidence', 1)\n",
      "('solicit', 1)\n",
      "('Cathedral', 1)\n",
      "('Mexico', 1)\n",
      "('Jung', 1)\n",
      "('thought', 1)\n",
      "('Relax', 1)\n",
      "('Jails', 1)\n",
      "('One', 1)\n",
      "('that’s', 1)\n",
      "('John', 1)\n",
      "('Wirecutter', 1)\n",
      "('Lifestyle', 1)\n",
      "('Lying', 1)\n",
      "('Yann', 1)\n",
      "('Several', 1)\n",
      "('collectors', 1)\n",
      "('heated', 1)\n",
      "('Living', 1)\n",
      "('Press', 1)\n",
      "('surgical', 1)\n",
      "('Warner', 1)\n",
      "('Sensational', 1)\n",
      "('Letter', 1)\n",
      "('Difficult', 1)\n",
      "('BokatLindell', 1)\n",
      "('Over', 1)\n",
      "('Myers', 1)\n",
      "('Steel', 1)\n",
      "('actor', 1)\n",
      "('N95', 1)\n",
      "('Williams', 1)\n",
      "('Nick', 1)\n",
      "('figure', 1)\n",
      "('Deal', 1)\n",
      "('SEARCH', 1)\n",
      "('Accuser', 1)\n",
      "('Ways', 1)\n",
      "('Karen', 1)\n",
      "('health', 1)\n",
      "('Mandates', 1)\n",
      "('Adam', 1)\n",
      "('Die', 1)\n",
      "('Lost', 1)\n",
      "('Ron', 1)\n",
      "('Happening', 1)\n",
      "('Just', 1)\n",
      "('Iconoclast', 1)\n",
      "('angry', 1)\n",
      "('Subdued', 1)\n",
      "('reboot', 1)\n",
      "('Down', 1)\n",
      "('big', 1)\n",
      "('Five', 1)\n",
      "('中文', 1)\n",
      "('judge', 1)\n",
      "('120917', 1)\n",
      "('Tips', 1)\n",
      "('agenda', 1)\n",
      "('Oyster', 1)\n",
      "('trickier', 1)\n",
      "('Turns', 1)\n",
      "('hedge', 1)\n",
      "('Ethan', 1)\n",
      "('migrants', 1)\n",
      "('owner', 1)\n",
      "('GM’s', 1)\n",
      "('Gathering', 1)\n",
      "('Sitemap', 1)\n",
      "('‘Hell', 1)\n",
      "('Hanna', 1)\n",
      "('divorce', 1)\n",
      "('Samantha', 1)\n",
      "('Ultrarich', 1)\n",
      "('Doing', 1)\n",
      "('Sublime', 1)\n",
      "('concerned', 1)\n",
      "('GutierrezAssociated', 1)\n",
      "('Sent', 1)\n",
      "('Boxed', 1)\n",
      "('Match', 1)\n",
      "('Abortions', 1)\n",
      "('Ask', 1)\n",
      "('Still', 1)\n",
      "('brighter', 1)\n",
      "('BhaskarThe', 1)\n",
      "('Prosecution', 1)\n",
      "('plans', 1)\n",
      "('evoked', 1)\n",
      "('Classes', 1)\n",
      "('generations', 1)\n",
      "('Between', 1)\n",
      "('Son', 1)\n",
      "('Roman', 1)\n",
      "('Folk', 1)\n",
      "('security', 1)\n",
      "('Time', 1)\n",
      "('Muscle', 1)\n",
      "('Gods', 1)\n",
      "('illustration', 1)\n",
      "('elements', 1)\n",
      "('searching', 1)\n",
      "('Crash', 1)\n",
      "('2022', 1)\n",
      "('Potter', 1)\n",
      "('Disrupting', 1)\n",
      "('China’s', 1)\n",
      "('Yechan', 1)\n",
      "('changed', 1)\n",
      "('Would', 1)\n",
      "('Flatbreads', 1)\n",
      "('Parents', 1)\n",
      "('Were', 1)\n",
      "('Oscar', 1)\n",
      "('Accept', 1)\n",
      "('projects', 1)\n",
      "('McQuade', 1)\n",
      "('Truck', 1)\n",
      "('School', 1)\n",
      "('Soon', 1)\n",
      "('Shuai', 1)\n",
      "('struggling', 1)\n",
      "('commit', 1)\n",
      "('Resilience', 1)\n",
      "('Experts', 1)\n",
      "('collect', 1)\n",
      "('Subscribers', 1)\n",
      "('Analysis', 1)\n",
      "('receive', 1)\n",
      "('Again', 1)\n",
      "('Jan', 1)\n",
      "('Scrivani', 1)\n",
      "('Years', 1)\n",
      "('Open', 1)\n",
      "('Kelly', 1)\n",
      "('sturdy', 1)\n",
      "('Crossword', 1)\n",
      "('Women', 1)\n",
      "('Christina', 1)\n",
      "('abortion', 1)\n",
      "('Echoing', 1)\n",
      "('2016', 1)\n",
      "('wrong', 1)\n",
      "('offers', 1)\n",
      "('Money', 1)\n",
      "('suggestion', 1)\n",
      "('airplane', 1)\n",
      "('agony', 1)\n",
      "('reduced', 1)\n",
      "('Tom', 1)\n",
      "('gains', 1)\n",
      "('chain', 1)\n",
      "('projector', 1)\n",
      "('Pans', 1)\n",
      "('EpoxydudeGetty', 1)\n",
      "('Sign', 1)\n",
      "('hand', 1)\n",
      "('Magic', 1)\n",
      "('Avoid', 1)\n",
      "('Sentenced', 1)\n",
      "('pet', 1)\n",
      "('CorumEPA', 1)\n",
      "('dispute', 1)\n",
      "('consumer', 1)\n",
      "('weekend', 1)\n",
      "('“What’s', 1)\n",
      "('Hero', 1)\n",
      "('At', 1)\n",
      "('primary', 1)\n",
      "('Week', 1)\n",
      "('wind', 1)\n",
      "('citizens', 1)\n",
      "('🎁', 1)\n",
      "('seasonal', 1)\n",
      "('Include', 1)\n",
      "('instinctual', 1)\n",
      "('head', 1)\n",
      "('Rikers', 1)\n",
      "('To', 1)\n",
      "('rulings', 1)\n",
      "('tough', 1)\n",
      "('Britain', 1)\n",
      "('indoors', 1)\n",
      "('psychotherapist', 1)\n",
      "('Collide', 1)\n",
      "('change', 1)\n",
      "('flipped', 1)\n",
      "('Killed', 1)\n",
      "('eager', 1)\n",
      "('men', 1)\n",
      "('Up', 1)\n",
      "('Code', 1)\n",
      "('Effect', 1)\n",
      "('happily', 1)\n",
      "('Nuts', 1)\n",
      "('Presence', 1)\n",
      "('bridge', 1)\n",
      "('Glitz', 1)\n",
      "('Examines', 1)\n",
      "('player', 1)\n",
      "('Gouda', 1)\n",
      "('school', 1)\n",
      "('Big', 1)\n",
      "('Help', 1)\n",
      "('McWhorter', 1)\n",
      "('Out', 1)\n",
      "('Krugman', 1)\n",
      "('4th', 1)\n",
      "('Spencer', 1)\n",
      "('vaccination', 1)\n",
      "('acknowledged', 1)\n",
      "('sitting', 1)\n",
      "('Log', 1)\n",
      "('Store', 1)\n",
      "('handling', 1)\n",
      "('medical', 1)\n",
      "('Tornadoes', 1)\n",
      "('PowerPoint', 1)\n",
      "('Thompson', 1)\n",
      "('Consult', 1)\n",
      "('charge', 1)\n",
      "('oven', 1)\n",
      "('cleaned', 1)\n",
      "('Contact', 1)\n",
      "('City', 1)\n",
      "('Nesmith', 1)\n",
      "('Estate', 1)\n",
      "('amp', 1)\n",
      "('13', 1)\n",
      "('Sale', 1)\n",
      "('Murray', 1)\n",
      "('‘Lived', 1)\n",
      "('rose', 1)\n",
      "('Proud', 1)\n",
      "('inspired', 1)\n",
      "('Won’t', 1)\n",
      "('censor', 1)\n",
      "('explicit', 1)\n",
      "('Jamelle', 1)\n",
      "('drafted', 1)\n",
      "('touch', 1)\n",
      "('energy', 1)\n",
      "('feels', 1)\n",
      "('Isn’t', 1)\n",
      "('Virus', 1)\n",
      "('Upend', 1)\n",
      "('Apple', 1)\n",
      "('PostRoe', 1)\n",
      "('Anna', 1)\n",
      "('ritual', 1)\n",
      "('Testifies', 1)\n",
      "('cases', 1)\n",
      "('Killer', 1)\n",
      "('European', 1)\n",
      "('masks', 1)\n",
      "('Trial', 1)\n",
      "('Transcripts', 1)\n",
      "('Spelling', 1)\n",
      "('rich', 1)\n",
      "('Copy', 1)\n",
      "('Well’s', 1)\n",
      "('members', 1)\n",
      "('trappings', 1)\n",
      "('14day', 1)\n",
      "('26', 1)\n",
      "('presents', 1)\n",
      "('federal', 1)\n",
      "('Dole', 1)\n",
      "('Little', 1)\n",
      "('Shellfish', 1)\n",
      "('struggled', 1)\n",
      "('Jere', 1)\n",
      "('Drive', 1)\n",
      "('Bouie', 1)\n",
      "('situations', 1)\n",
      "('Ashley', 1)\n",
      "('Doomsday', 1)\n",
      "('Cultivate', 1)\n",
      "('Dunn', 1)\n",
      "('Arabic', 2)\n",
      "('break', 2)\n",
      "('Economy', 2)\n",
      "('Facts', 2)\n",
      "('Schedule', 2)\n",
      "('Mich', 2)\n",
      "('Malosh', 2)\n",
      "('Freedom', 2)\n",
      "('Investigations', 2)\n",
      "('years', 2)\n",
      "('Mission', 2)\n",
      "('Stay', 2)\n",
      "('Binge', 2)\n",
      "('Inside', 2)\n",
      "('bags', 2)\n",
      "('increases', 2)\n",
      "('Coy', 2)\n",
      "('Relationships', 2)\n",
      "('Privacy', 2)\n",
      "('T', 2)\n",
      "('flying', 2)\n",
      "('Presidency', 2)\n",
      "('site', 2)\n",
      "('Could', 2)\n",
      "('Golf', 2)\n",
      "('Football', 2)\n",
      "('Supreme', 2)\n",
      "('friends', 2)\n",
      "('Architecture', 2)\n",
      "('HLN', 2)\n",
      "('experts', 2)\n",
      "('Impact', 2)\n",
      "('Opinion', 2)\n",
      "('AZ', 2)\n",
      "('Peter', 2)\n",
      "('Vaccine', 2)\n",
      "('First', 2)\n",
      "('planning', 2)\n",
      "('CNNVR', 2)\n",
      "('Luxury', 2)\n",
      "('Innovate', 2)\n",
      "('Middle', 2)\n",
      "('Mindfulness', 2)\n",
      "('Heroes', 2)\n",
      "('Profiles', 2)\n",
      "('Ad', 2)\n",
      "('don’t', 2)\n",
      "('Ahead', 2)\n",
      "('Edition', 2)\n",
      "('Europe', 2)\n",
      "('Equals', 2)\n",
      "('Asia', 2)\n",
      "('Coronavirus', 2)\n",
      "('Well', 2)\n",
      "('space', 2)\n",
      "('Elections', 2)\n",
      "('Digital', 2)\n",
      "('election', 2)\n",
      "('court', 2)\n",
      "('gift', 2)\n",
      "('Tennis', 2)\n",
      "('reality', 2)\n",
      "('Minn', 2)\n",
      "('‘The', 2)\n",
      "('Photos', 2)\n",
      "('Design', 2)\n",
      "('Global', 2)\n",
      "('County', 2)\n",
      "('require', 2)\n",
      "('Canada', 2)\n",
      "('Screen', 2)\n",
      "('gatherings', 2)\n",
      "('Longform', 2)\n",
      "('letters', 2)\n",
      "('detected', 2)\n",
      "('Success', 2)\n",
      "('Wildfire', 2)\n",
      "('Nothing', 2)\n",
      "('bans', 2)\n",
      "('trackers', 2)\n",
      "('Esports', 2)\n",
      "('Fitness', 2)\n",
      "('ParkerPope', 2)\n",
      "('Tamales', 2)\n",
      "('Follow', 2)\n",
      "('Stars', 2)\n",
      "('Tokyo', 2)\n",
      "('Its', 2)\n",
      "('Beatles', 2)\n",
      "('Markets', 2)\n",
      "('unvaccinated', 2)\n",
      "('Leadership', 2)\n",
      "('Be', 2)\n",
      "('Inflation', 2)\n",
      "('weeks', 2)\n",
      "('Articles', 2)\n",
      "('I’m', 2)\n",
      "('Cable', 2)\n",
      "('pregnancy', 2)\n",
      "('Accessibility', 2)\n",
      "('Gadget', 2)\n",
      "('Sarahbeth', 2)\n",
      "('Shutterstock', 2)\n",
      "('Studios', 2)\n",
      "('Cities', 2)\n",
      "('From', 2)\n",
      "('Choices', 2)\n",
      "('Had', 2)\n",
      "('After', 2)\n",
      "('Foreseeable', 2)\n",
      "('content', 2)\n",
      "('winter', 2)\n",
      "('On', 2)\n",
      "('Live', 2)\n",
      "('Jersey', 2)\n",
      "('E', 2)\n",
      "('safely', 2)\n",
      "('Weather', 2)\n",
      "('Destinations', 2)\n",
      "('10', 2)\n",
      "('picture', 2)\n",
      "('Films', 2)\n",
      "('Transformed', 2)\n",
      "('Upstarts', 2)\n",
      "('Project', 2)\n",
      "('county', 2)\n",
      "('Kingdom', 2)\n",
      "('Magazine', 2)\n",
      "('Nursing', 2)\n",
      "('Climbing', 2)\n",
      "('Degrees', 2)\n",
      "('France', 2)\n",
      "('Fashion', 2)\n",
      "('day', 2)\n",
      "('Getting', 2)\n",
      "('Tara', 2)\n",
      "('ManeyThe', 2)\n",
      "('Breaking', 2)\n",
      "('NH', 2)\n",
      "('Site', 2)\n",
      "('Motorsport', 2)\n",
      "('Policy', 2)\n",
      "('India', 2)\n",
      "('This', 2)\n",
      "('it’s', 2)\n",
      "('Network', 2)\n",
      "('In', 2)\n",
      "('Australia', 2)\n",
      "('Americas', 2)\n",
      "('Perspectives', 2)\n",
      "('Challenge', 2)\n",
      "('Climate', 2)\n",
      "('Innovative', 2)\n",
      "('Future', 2)\n",
      "('eat', 2)\n",
      "('Give', 2)\n",
      "('long', 2)\n",
      "('Company', 2)\n",
      "('decision', 2)\n",
      "('Earth', 2)\n",
      "('holiday', 2)\n",
      "('Clean', 2)\n",
      "('Listen', 2)\n",
      "('Call', 2)\n",
      "('Committee', 2)\n",
      "('Sleep', 2)\n",
      "('Advertise', 2)\n",
      "('Storm', 2)\n",
      "('pandemic', 2)\n",
      "('Formula', 2)\n",
      "('Photo', 2)\n",
      "('Beauty', 2)\n",
      "('Drink', 2)\n",
      "('East', 2)\n",
      "('We’re', 3)\n",
      "('Español', 3)\n",
      "('©', 3)\n",
      "('Mark', 3)\n",
      "('Search', 3)\n",
      "('Terms', 3)\n",
      "('public', 3)\n",
      "('Learn', 3)\n",
      "('Us', 3)\n",
      "('guide', 3)\n",
      "('2020', 3)\n",
      "('Newsletters', 3)\n",
      "('Washington', 3)\n",
      "('Better', 3)\n",
      "('Small', 3)\n",
      "('Michael', 3)\n",
      "('advice', 3)\n",
      "('Trump', 3)\n",
      "('holidays', 3)\n",
      "('Entertainment', 3)\n",
      "('time', 3)\n",
      "('China', 3)\n",
      "('Like', 3)\n",
      "('you’re', 3)\n",
      "('short', 3)\n",
      "('With', 3)\n",
      "('Arts', 3)\n",
      "('Look', 3)\n",
      "('Skip', 3)\n",
      "('That', 3)\n",
      "('Other', 3)\n",
      "('Home', 3)\n",
      "('About', 3)\n",
      "('Tracking', 3)\n",
      "('Do', 3)\n",
      "('UK', 3)\n",
      "('social', 3)\n",
      "('Habits', 3)\n",
      "('Holiday', 3)\n",
      "('Shows', 3)\n",
      "('Where', 3)\n",
      "('Texas', 3)\n",
      "('Make', 3)\n",
      "('Features', 4)\n",
      "('Style', 4)\n",
      "('But', 4)\n",
      "('Travel', 4)\n",
      "('Business', 4)\n",
      "('2021', 4)\n",
      "('family', 4)\n",
      "('Getty', 4)\n",
      "('vaccinations', 4)\n",
      "('Life', 4)\n",
      "('Your', 4)\n",
      "('Why', 4)\n",
      "('Politics', 4)\n",
      "('As', 4)\n",
      "('Here’s', 4)\n",
      "('Health', 4)\n",
      "('Andrew', 4)\n",
      "('Culture', 4)\n",
      "('Court', 4)\n",
      "('More', 4)\n",
      "('Is', 4)\n",
      "('Africa', 4)\n",
      "('Tracker', 4)\n",
      "('Food', 5)\n",
      "('What', 5)\n",
      "('reading', 5)\n",
      "('You', 5)\n",
      "('David', 5)\n",
      "('International', 5)\n",
      "('Media', 5)\n",
      "('main', 5)\n",
      "('Continue', 5)\n",
      "('All', 5)\n",
      "('Tech', 5)\n",
      "('President', 5)\n",
      "('Advertisement', 5)\n",
      "('Can', 5)\n",
      "('States', 5)\n",
      "('Celebrating', 6)\n",
      "('Are', 6)\n",
      "('United', 6)\n",
      "('We', 6)\n",
      "('Sports', 6)\n",
      "('It', 6)\n",
      "('Work', 6)\n",
      "('TV', 6)\n",
      "('story', 6)\n",
      "('Biden', 6)\n",
      "('For', 6)\n",
      "('Images', 6)\n",
      "('Video', 6)\n",
      "('If', 7)\n",
      "('A', 7)\n",
      "('Omicron', 7)\n",
      "('mask', 8)\n",
      "('Holidays', 8)\n",
      "('Videos', 8)\n",
      "('›', 8)\n",
      "('World', 9)\n",
      "('Through', 10)\n",
      "('Get', 11)\n",
      "('News', 11)\n",
      "('How', 16)\n",
      "('US', 17)\n",
      "('CNN', 19)\n",
      "('Times', 20)\n",
      "('York', 23)\n",
      "('New', 28)\n",
      "('The', 30)\n"
     ]
    }
   ],
   "source": [
    "# 3. 반복자 관련 메소드 테스트\n",
    "for i in w6:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb14dd",
   "metadata": {},
   "source": [
    "### 소감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae74d57",
   "metadata": {},
   "source": [
    "이전 수업시간에 말씀해주신바와 같이 전반적으로 저번주보다는 수월하게 문제를 해결하였습니다.\n",
    "Incremental 문제에서 코드 리팩토링이 생각보다 시간을 많이 걸렸는데요. 저번 주까지 작성한 코드는 클래스없이 오직 함수 간의 관계로 설계를 했었는데, 리팩토링 과정을 통해 함수별 실행 빈도를 줄이고, 코드의 가독성을 높힐 수 있는 시간이 되었습니다. 클래스 내에 정의되어야 할 함수가 문제에 제시된 것만 포함되어야 할 것 같아, 우선은 해당 함수들로만 구현하였는데 해당 조건부가 없다면 지금보다 한 단계 더 짧은 코드로도 설계 가능할 것 같습니다. <br>끝으로, 한 학기 수업을 들으면서 총평을 말씀드리면, 처음에는 파이썬에 익숙하지 않아 우물쭈물하고 과제 해결에도 버거웠는데, 마지막 주차가 다가올수록 확실히 성장해가고 있구나, 라는 느낌을 받을 수 있는 수업이었습니다. 타 교과목의 경우, 텀프로젝트를 직접 정해서 진행하는 경우가 많은데, 이 때는 주제를 정하느라 확실히 코드 작성에 정성을 들일 시간이 부족했습니다. 하지만, 교수님의 텀프로젝트는 주차별 프로젝트 과제를 단계별로 주셔서, 확실히 코드 작성과 함께 코드가 어떻게 구성되어 있고, 설계는 이렇게 하면 되는구나 라는 감을 잡고 코드를 음미할 수 있는 시간이 되었습니다. 한 학기동안 고생하셨습니다. 감사합니다. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
